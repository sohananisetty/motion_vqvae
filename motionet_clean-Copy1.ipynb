{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcaaaca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d978f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120cfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "import visualize.plot_3d_global as plot_3d\n",
    "from glob import glob\n",
    "def to_xyz(motion, mean ,std , j = 22):\n",
    "    motion_xyz = recover_from_ric(motion.cpu().float()*std+mean, j)\n",
    "    motion_xyz = motion_xyz.reshape(motion.shape[0],-1, j, 3)\n",
    "    return motion_xyz\n",
    "\n",
    "            \n",
    "def sample_render(motion_xyz , name , save_path):\n",
    "    print(f\"render start\")\n",
    "    \n",
    "    gt_pose_vis = plot_3d.draw_to_batch(motion_xyz.numpy(),None, [os.path.join(save_path,name + \".gif\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fb7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75437290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = MotionCollator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50424dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 60 - 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 37.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = VQVarLenMotionDataset(\"t2m\", split = \"render\" , max_length_seconds = 10, data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D\")\n",
    "train_loader = DATALoader(train_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc774b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQVarLenMotionDataset(\"aist\", split = \"render\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , num_stages = 6 ,min_length_seconds=20, max_length_seconds=30)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32fea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 600\n"
     ]
    }
   ],
   "source": [
    "aist_loader.dataset.set_stage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da01534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 159, 263])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for aist_batch in aist_loader:\n",
    "    break\n",
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99107113",
   "metadata": {},
   "source": [
    "## Trans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e491b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ca3b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([210000.])\n"
     ]
    }
   ],
   "source": [
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58013d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b565e8",
   "metadata": {},
   "source": [
    "## Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fb8e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 191])\n"
     ]
    }
   ],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"].cuda())\n",
    "print(ind.shape)\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f010f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.empty(aist_batch[\"motion\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bf733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c188c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"][:,:400].cuda())\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41c3dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant , out_motion = vqvae_model.decode(ind[:,400:].to(torch.long).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5411013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,400:] = out_motion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d67a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_og_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "241a5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion_ind_400\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ebcdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(0,1024,(1,60))\n",
    "quant , out_motion = vqvae_model.decode(indices.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90379db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f95c09",
   "metadata": {},
   "source": [
    "## Music Eval stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df396922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ad8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "from utils.aist_metrics import calculate_fid_scores\n",
    "from utils.aist_metrics.calculate_fid_scores import calculate_avg_distance, extract_feature,calculate_frechet_feature_distance,calculate_frechet_distance\n",
    "from utils.aist_metrics.features import kinetic,manual\n",
    "from utils.aist_metrics.calculate_beat_scores import motion_peak_onehot,alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088f2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import MotionCollatorConditional, TransMotionDatasetConditional,VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14fb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae, evaluate_music_motion_generative,evaluate_music_motion_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24604a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for aist_batch in tqdm(aist_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b85a62",
   "metadata": {},
   "source": [
    "### Const len trained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c1c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([85000.])\n"
     ]
    }
   ],
   "source": [
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/const_len/trans_768_768_aist/vqvae_motion.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ea564d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2763786008230453"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.23/0.243 * 0.292"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365a3a3",
   "metadata": {},
   "source": [
    "## Evaluate Music Motion transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9ea9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/var_len_768_768_aist.yaml\"\n",
    "encodec_sine = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_sine_aist/var_len_768_768_sine_aist.yaml\"\n",
    "librosa = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_35/var_len_768_768_aist_35.yaml\"\n",
    "encodec_prob50 = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_mask_prob50/trans_768_768_albi_aist_mask_prob50.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da714b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([205000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "trans_option = \"encodec_sine\"\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(encodec_sine)\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"{os.path.dirname(encodec_sine)}/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcda749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_encoding_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "audio_features_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/audio_features/\"\n",
    "use35 = False\n",
    "if trans_option == \"librosa\":\n",
    "    audio_encoding_dir = audio_features_dir\n",
    "    use35 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f82831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81752e",
   "metadata": {},
   "source": [
    "## Evaluate Music Motion Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f67202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from render_final import hml2aist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae, evaluate_music_motion_generative,evaluate_music_motion_generative2,evaluate_music_motion_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b667473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1040.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e41c4914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:14<00:00, 27.78it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 29.94it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 29.81it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.30it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.17it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.23it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.62it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.41it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.31it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.56it/s]\n",
      "100%|██████████| 400/400 [00:12<00:00, 30.96it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.33it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 29.87it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.41it/s]\n",
      "100%|██████████| 400/400 [00:13<00:00, 30.43it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.37it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.60it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.65it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.40it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.85it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.15it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.51it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.44it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.59it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.66it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 49.55it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.30it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.94it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.56it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.89it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.41it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.10it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.76it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.84it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.80it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 52.07it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.66it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 50.56it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.68it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 51.79it/s]\n",
      "100%|██████████| 40/40 [07:34<00:00, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  7.162948547746254 Diversity_k: 9.617357408618316\n",
      "FID_g:  12.577118332144806 Diversity_g: 7.296678166206067\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.208\n",
      "\n",
      "\\PFC score on real data: 2.113\n",
      "\n",
      "\\PFC score on generated data: 2.339\n",
      "\n",
      "best_fid_k 7.162948547746254\n",
      "best_fid_g 12.577118332144806\n",
      "best_div_k 9.617357408618316\n",
      "best_div_g 7.296678166206067\n",
      "best_beat_align 0.244130060202235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_music import evaluate_music_motion_generative\n",
    "print(\"pretrained mix\")\n",
    "best_fid_k = []\n",
    "best_fid_g = []\n",
    "best_div_k = []\n",
    "best_div_g = []\n",
    "best_beat_align = []\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    gen_motions , a,b,c,d,e = evaluate_music_motion_generative(aist_loader , vqvae_model= vqvae_model ,net = trans_model,use35=use35)\n",
    "    best_fid_k.append(a)\n",
    "    best_fid_g.append(b)\n",
    "    best_div_k.append(c)\n",
    "    best_div_g.append(d)\n",
    "    best_beat_align.append(e)\n",
    "\n",
    "    \n",
    "print(\"best_fid_k\" , np.mean(best_fid_k))\n",
    "print(\"best_fid_g\" , np.mean(best_fid_g))\n",
    "print(\"best_div_k\" , np.mean(best_div_k))\n",
    "print(\"best_div_g\" , np.mean(best_div_g))\n",
    "print(\"best_beat_align\" , np.mean(best_beat_align))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8df4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b138a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_features = {\n",
    "        \"kinetic\": [np.load(f) for f in glob(\"/srv/share/datasets/AIST/aist_features/*_kinetic.npy\")],\n",
    "        \"manual\": [np.load(f) for f in glob(\"/srv/share/datasets/AIST/aist_features/*_manual.npy\")],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6d63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1ca12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.aist_metrics.features import kinetic,manual\n",
    "from utils.aist_metrics.calculate_beat_scores import motion_peak_onehot,alignment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb40cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2b0dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 213, 263]) torch.Size([1, 400, 263]) mKR2 gPO_sBM_cAll_d11_mPO1_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/scratch/sanisetty3/music_motion/motion_vqvae/render_final.py:243: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vertices, rotations, global_orient, out, x_translations = rot2xyz(torch.tensor(motion_tensor).clone(), mask=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 1/40 [04:10<2:42:55, 250.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([213, 3, 3]) torch.Size([213, 23, 3, 3]) torch.Size([1, 3, 213])\n",
      "torch.Size([1, 159, 263]) torch.Size([1, 400, 263]) mKR2 gLH_sBM_cAll_d17_mLH4_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [07:50<2:32:55, 241.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([159, 3, 3]) torch.Size([159, 23, 3, 3]) torch.Size([1, 3, 159])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gJS_sBM_cAll_d01_mJS3_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [12:47<2:39:05, 257.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 159, 263]) torch.Size([1, 400, 263]) mKR2 gLH_sBM_cAll_d18_mLH4_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [18:10<2:46:34, 277.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([159, 3, 3]) torch.Size([159, 23, 3, 3]) torch.Size([1, 3, 159])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gLO_sBM_cAll_d15_mLO2_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [22:44<2:41:13, 276.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gKR_sBM_cAll_d28_mKR2_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6/40 [27:05<2:33:59, 271.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gMH_sBM_cAll_d24_mMH3_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7/40 [30:33<2:18:56, 252.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gBR_sBM_cAll_d04_mBR0_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [34:28<2:12:03, 247.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 147, 263]) torch.Size([1, 400, 263]) mKR2 gJB_sBM_cAll_d08_mJB5_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [39:28<2:15:58, 263.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147, 3, 3]) torch.Size([147, 23, 3, 3]) torch.Size([1, 3, 147])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gMH_sBM_cAll_d24_mMH3_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [44:32<2:17:39, 275.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gWA_sBM_cAll_d25_mWA0_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [48:58<2:11:42, 272.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 147, 263]) torch.Size([1, 400, 263]) mKR2 gJB_sBM_cAll_d09_mJB5_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [53:34<2:07:45, 273.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147, 3, 3]) torch.Size([147, 23, 3, 3]) torch.Size([1, 3, 147])\n",
      "torch.Size([1, 141, 263]) torch.Size([1, 400, 263]) mKR2 gHO_sBM_cAll_d20_mHO5_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [58:23<2:05:13, 278.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([141, 3, 3]) torch.Size([141, 23, 3, 3]) torch.Size([1, 3, 141])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gJS_sBM_cAll_d01_mJS3_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [1:03:09<2:01:32, 280.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gJS_sBM_cAll_d03_mJS3_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [1:07:32<1:54:40, 275.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gBR_sBM_cAll_d04_mBR0_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [1:12:33<1:53:10, 282.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gKR_sBM_cAll_d30_mKR2_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [1:17:33<1:50:30, 288.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 147, 263]) torch.Size([1, 400, 263]) mKR2 gJB_sBM_cAll_d09_mJB5_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [1:22:07<1:44:07, 283.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147, 3, 3]) torch.Size([147, 23, 3, 3]) torch.Size([1, 3, 147])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gLO_sBM_cAll_d15_mLO2_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [1:28:26<1:49:21, 312.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gWA_sBM_cAll_d26_mWA0_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [1:34:12<1:47:29, 322.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gLO_sBM_cAll_d13_mLO2_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [1:39:06<1:39:24, 313.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 159, 263]) torch.Size([1, 400, 263]) mKR2 gLH_sBM_cAll_d18_mLH4_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [1:44:21<1:34:14, 314.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([159, 3, 3]) torch.Size([159, 23, 3, 3]) torch.Size([1, 3, 159])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gKR_sBM_cAll_d30_mKR2_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [1:49:01<1:26:08, 304.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gMH_sBM_cAll_d22_mMH3_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [1:53:30<1:18:13, 293.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 191, 263]) torch.Size([1, 400, 263]) mKR2 gKR_sBM_cAll_d28_mKR2_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [1:58:05<1:11:59, 287.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 3, 3]) torch.Size([191, 23, 3, 3]) torch.Size([1, 3, 191])\n",
      "torch.Size([1, 159, 263]) torch.Size([1, 400, 263]) mKR2 gLH_sBM_cAll_d17_mLH4_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [2:02:23<1:05:06, 279.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([159, 3, 3]) torch.Size([159, 23, 3, 3]) torch.Size([1, 3, 159])\n",
      "torch.Size([1, 141, 263]) torch.Size([1, 400, 263]) mKR2 gHO_sBM_cAll_d20_mHO5_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [2:06:34<58:36, 270.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([141, 3, 3]) torch.Size([141, 23, 3, 3]) torch.Size([1, 3, 141])\n",
      "torch.Size([1, 147, 263]) torch.Size([1, 400, 263]) mKR2 gJB_sBM_cAll_d08_mJB5_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [2:10:35<52:21, 261.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147, 3, 3]) torch.Size([147, 23, 3, 3]) torch.Size([1, 3, 147])\n",
      "torch.Size([1, 141, 263]) torch.Size([1, 400, 263]) mKR2 gHO_sBM_cAll_d21_mHO5_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [2:14:24<46:12, 252.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([141, 3, 3]) torch.Size([141, 23, 3, 3]) torch.Size([1, 3, 141])\n",
      "torch.Size([1, 174, 263]) torch.Size([1, 400, 263]) mKR2 gMH_sBM_cAll_d22_mMH3_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [2:18:19<41:06, 246.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([174, 3, 3]) torch.Size([174, 23, 3, 3]) torch.Size([1, 3, 174])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gBR_sBM_cAll_d05_mBR0_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [2:22:42<37:45, 251.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gWA_sBM_cAll_d25_mWA0_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [2:27:45<35:36, 267.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 213, 263]) torch.Size([1, 400, 263]) mKR2 gPO_sBM_cAll_d10_mPO1_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [2:32:14<31:12, 267.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([213, 3, 3]) torch.Size([213, 23, 3, 3]) torch.Size([1, 3, 213])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gBR_sBM_cAll_d05_mBR0_ch01\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([400, 3, 3]) torch.Size([400, 23, 3, 3]) torch.Size([1, 3, 400])\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [2:36:42<26:46, 267.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 3, 3]) torch.Size([239, 23, 3, 3]) torch.Size([1, 3, 239])\n",
      "torch.Size([1, 239, 263]) torch.Size([1, 400, 263]) mKR2 gWA_sBM_cAll_d26_mWA0_ch02\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "aist_motions = []\n",
    "musics = []\n",
    "gt_motions = []\n",
    "motion_names=  []\n",
    "for gt_motion , motion, motion_name in tqdm(gen_motions):\n",
    "    music_name = motion_name.split('_')[-2]\n",
    "    print(gt_motion.shape, motion.shape, audio_name, motion_name)\n",
    "    \n",
    "    motion_names.append(motion_name)\n",
    "    \n",
    "    motion_xyz = to_xyz(motion.detach().cpu() , mean= aist_ds.mean , std = aist_ds.std)\n",
    "    aist = hml2aist(motion_xyz[0].cpu().numpy() )\n",
    "    aist_motions.append(aist)\n",
    "    \n",
    "    motion_xyz = to_xyz(gt_motion.detach().cpu(), mean= aist_ds.mean , std = aist_ds.std)\n",
    "    gt = hml2aist(motion_xyz[0].cpu().numpy())\n",
    "    gt_motions.append(gt)\n",
    "    \n",
    "    \n",
    "    audio_feature = np.load(os.path.join(audio_features_dir, f\"{audio_name}.npy\"))\n",
    "    musics.append(audio_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8352d",
   "metadata": {},
   "source": [
    "### HML2AIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364048bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smplx import SMPL\n",
    "smpl = SMPL(model_path=\"/srv/share/datasets/AIST/smpl_models/\", gender='MALE', batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199aa9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_features[\"kinetic\"].append(extract_feature(keypoints3d_gt, \"kinetic\"))\n",
    "real_features[\"manual\"].append(extract_feature(keypoints3d_gt, \"manual\"))\n",
    "\n",
    "result_features[\"kinetic\"].append(extract_feature(keypoints3d_pred, \"kinetic\"))\n",
    "result_features[\"manual\"].append(extract_feature(keypoints3d_pred, \"manual\"))\n",
    "\n",
    "real_pfc.append(calc_physical_score(keypoints3d_gt))\n",
    "pred_pfc.append(calc_physical_score(keypoints3d_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "motion_beats = motion_peak_onehot(keypoints3d_gt[:mot_len])\n",
    "# get real data music beats\n",
    "audio_name = motion_name.split(\"_\")[-2]\n",
    "\n",
    "audio_feature = np.load(os.path.join(audio_feature_dir, f\"{audio_name}.npy\"))\n",
    "audio_beats = audio_feature[:mot_len, -1] # last dim is the music beats\n",
    "# get beat alignment scores\n",
    "beat_score = alignment_score(audio_beats, motion_beats, sigma=1)\n",
    "beat_scores_real.append(beat_score)\n",
    "\n",
    "\n",
    "motion_beats = motion_peak_onehot(keypoints3d_pred[:mot_len])\n",
    "beat_score_pred = alignment_score(audio_beats, motion_beats, sigma=1)\n",
    "beat_scores_pred.append(beat_score_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ba636",
   "metadata": {},
   "source": [
    "### Long motion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21c34132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [01:04<00:00, 29.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds_train = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader_train = DATALoader(aist_ds_train,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83aca1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in aist_loader_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6c31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbdf1438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/900 [00:00<00:14, 62.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:20<00:00, 42.96it/s]\n",
      "100%|██████████| 900/900 [00:20<00:00, 43.03it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.70it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.74it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.69it/s]it]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.81it/s]it]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.37it/s]]  \n",
      "100%|██████████| 900/900 [00:21<00:00, 42.73it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.74it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.77it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.46it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.69it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.79it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.13it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.60it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.56it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.75it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.85it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.64it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.51it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.42it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.66it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.72it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.61it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.67it/s]s]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.61it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.68it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.33it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.43it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.21it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.10it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.07it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.13it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.28it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.59it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.57it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.56it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.52it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.70it/s]s]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.78it/s]s]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.53it/s]t]\n",
      " 95%|█████████▌| 1818/1910 [18:01<00:54,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  6.394353653410235 Diversity_k: 10.558077923262992\n",
      "FID_g:  8.632308692625102 Diversity_g: 7.294414699949869\n",
      "\\PFC score on real data: 1.677\n",
      "\n",
      "\\PFC score on generated data: 1.239\n",
      "\n",
      "\n",
      "Beat score on real data: 0.170\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.164\n",
      "\n",
      "best_fid_k 6.394353653410235\n",
      "best_fid_g 8.632308692625102\n",
      "best_div_k 10.558077923262992\n",
      "best_div_g 7.294414699949869\n",
      "best_beat_align 0.17011690074139812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"pretrained mix\")\n",
    "best_fid_k = []\n",
    "best_fid_g = []\n",
    "best_div_k = []\n",
    "best_div_g = []\n",
    "best_beat_align = []\n",
    "seq_len = 900\n",
    "for i in range(1):\n",
    "\n",
    "    a,b,c,d,e,f,g = evaluate_music_motion_generative2(aist_loader_train , vqvae_model= vqvae_model ,net = trans_model, use35 = use35,seq_len = seq_len)\n",
    "    best_fid_k.append(a)\n",
    "    best_fid_g.append(b)\n",
    "    best_div_k.append(c)\n",
    "    best_div_g.append(d)\n",
    "    best_beat_align.append(e)\n",
    "\n",
    "    \n",
    "print(\"best_fid_k\" , np.mean(best_fid_k))\n",
    "print(\"best_fid_g\" , np.mean(best_fid_g))\n",
    "print(\"best_div_k\" , np.mean(best_div_k))\n",
    "print(\"best_div_g\" , np.mean(best_div_g))\n",
    "print(\"best_beat_align\" , np.mean(best_beat_align))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eadc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "829c1b0b",
   "metadata": {},
   "source": [
    "## Eval using evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0744c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.evaluator_wrapper import AISTEvaluatorModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b24fdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_generative_extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7536746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "\n",
    "cfg_eval = get_cfg_defaults()\n",
    "cfg_eval.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/extractors/big/aist_extractor.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5d004d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 518.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.evaluator_dataset import EvaluatorMotionCollator, EvaluatorVarLenMotionDataset, EvaluatorMotionDataset\n",
    "aist_ds = EvaluatorMotionDataset(split = \"test\" ,data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" ,window_size = -1,librosa = use35 )\n",
    "collate_fn = EvaluatorMotionCollator()\n",
    "\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84ee9777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from:  /srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/extractors/big/extractors.pt steps:  tensor([95000.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "aist_evaluator = AISTEvaluatorModelWrapper(cfg_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ca5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b3ac2dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:05<00:00, 25.96it/s]\n",
      "100%|██████████| 191/191 [00:05<00:00, 36.13it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 55.90it/s]\n",
      "100%|██████████| 213/213 [00:03<00:00, 55.80it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 55.84it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 54.01it/s]\n",
      "100%|██████████| 213/213 [00:03<00:00, 54.64it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 53.85it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 53.96it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 55.07it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 55.62it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 55.22it/s]\n",
      "100%|██████████| 141/141 [00:02<00:00, 55.10it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 54.62it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 54.32it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 55.58it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 54.45it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 54.54it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 51.83it/s]\n",
      "100%|██████████| 213/213 [00:03<00:00, 54.35it/s]\n",
      "100%|██████████| 191/191 [00:04<00:00, 40.47it/s]\n",
      "100%|██████████| 159/159 [00:03<00:00, 41.44it/s]\n",
      "100%|██████████| 239/239 [00:05<00:00, 41.00it/s]\n",
      "100%|██████████| 141/141 [00:03<00:00, 40.88it/s]\n",
      "100%|██████████| 239/239 [00:05<00:00, 40.71it/s]\n",
      "100%|██████████| 174/174 [00:04<00:00, 40.19it/s]\n",
      "100%|██████████| 174/174 [00:04<00:00, 40.97it/s]\n",
      "100%|██████████| 174/174 [00:04<00:00, 40.62it/s]\n",
      "100%|██████████| 174/174 [00:04<00:00, 40.47it/s]\n",
      "100%|██████████| 239/239 [00:05<00:00, 40.29it/s]\n",
      "100%|██████████| 191/191 [00:04<00:00, 40.85it/s]\n",
      "100%|██████████| 239/239 [00:07<00:00, 32.77it/s]\n",
      "100%|██████████| 174/174 [00:04<00:00, 37.02it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 52.42it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 49.64it/s]\n",
      "100%|██████████| 159/159 [00:03<00:00, 47.89it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 54.68it/s]\n",
      "100%|██████████| 213/213 [00:03<00:00, 54.87it/s]\n",
      "100%|██████████| 141/141 [00:02<00:00, 55.54it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 55.11it/s]\n",
      "100%|██████████| 40/40 [02:41<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "70.26463 77.746445\n",
      "--> \t :, FID. 1.1213, Diversity Real. 1.2656, Diversity. 1.3185, R_precision_real. [0.075 0.15  0.175], R_precision. [0.025 0.05  0.1  ], matching_score_real. 1.7566158294677734, matching_score_pred. 1.9436611175537108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fids = []\n",
    "div_R = []\n",
    "div_p = []\n",
    "\n",
    "for i in range(1):\n",
    "    fid, diversity_real, diversity = evaluate_music_motion_generative_extractors(aist_loader , vqvae_model= vqvae_model ,net = trans_model, eval_wrapper = aist_evaluator, seq_len = 600)\n",
    "    fids.append(fid)\n",
    "    div_R.append(diversity_real)\n",
    "    div_p.append(diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979fbd3",
   "metadata": {},
   "source": [
    "Encodec: FID. 0.7455, Diversity Real. 1.3312, Diversity. 1.2632\n",
    "Sine: FID. 0.6938, Diversity Real. 1.3411, Diversity. 1.2442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8dd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "600 big\n",
    "Encodec: FID. 0.7329, Diversity Real. 1.3029, Diversity. 1.2565, R_precision_real. [0.65853659 0.92682927 1.        ], R_precision. [0.07317073 0.12195122 0.12195122], matching_score_real. 0.5742702949337843, matching_score_pred. 1.9448303594821836\n",
    "Encodec sine: FID. 0.7063, Diversity Real. 1.3348, Diversity. 1.2455, R_precision_real. [0.68292683 0.90243902 0.97560976], R_precision. [0.07317073 0.12195122 0.14634146], matching_score_real. 0.5801425561672304, matching_score_pred. 1.938593980742664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test abt 300 len big\n",
    "Encodec sine: FID. 1.0863, Diversity Real. 1.3563, Diversity. 1.3132, R_precision_real. [0.075 0.15  0.175], R_precision. [0.1   0.1   0.125], matching_score_real. 1.7566158294677734, matching_score_pred. 1.9094511032104493\n",
    "Encodec: FID. 1.1263, Diversity Real. 1.3098, Diversity. 1.3185, R_precision_real. [0.075 0.15  0.175], R_precision. [0.025 0.05  0.1  ], matching_score_real. 1.7566158294677734, matching_score_pred. 1.9520971298217773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "small 600\n",
    "Encodec sine: FID. 0.5658, Diversity Real. 1.3857, Diversity. 1.0602, R_precision_real. [0.56097561 0.68292683 0.7804878 ], R_precision. [0.04878049 0.07317073 0.09756098], matching_score_real. 0.9467918582078887, matching_score_pred. 1.7773874794564597\n",
    "Encodec: FID. 0.3988, Diversity Real. 1.2957, Diversity. 1.1036, R_precision_real. [0.53658537 0.68292683 0.73170732], R_precision. [0.04878049 0.07317073 0.17073171], matching_score_real. 0.9478622994771818, matching_score_pred. 1.5739107829768484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2594b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "322662b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:17<00:00, 45.63it/s]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.46it/s]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.20it/s]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.37it/s]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.31it/s]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.27it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.25it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.52it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.25it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.22it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.21it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.53it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.17it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.00it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.18it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.12it/s]]  \n",
      "100%|██████████| 800/800 [00:17<00:00, 45.19it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.10it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.03it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.11it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.15it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.07it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.26it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.13it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.18it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.19it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.49it/s]]  \n",
      "100%|██████████| 800/800 [00:17<00:00, 44.99it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.18it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 44.81it/s]it]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.21it/s]]  \n",
      "100%|██████████| 800/800 [00:17<00:00, 45.25it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.15it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.21it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.19it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 44.98it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.10it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 44.97it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.20it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.26it/s]]\n",
      "100%|██████████| 800/800 [00:17<00:00, 45.25it/s]]\n",
      " 45%|████▍     | 855/1910 [12:11<15:03,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seq_len = 800\n",
    "motion_annotation_list = []\n",
    "motion_pred_list = []\n",
    "\n",
    "music_annotation_list = []\n",
    "music_pred_list = []\n",
    "\n",
    "R_precision_real = 0\n",
    "R_precision = 0\n",
    "\n",
    "nb_sample = 0\n",
    "\n",
    "audio_dir = audio_feature_dir if use35 else audio_encoding_dir\n",
    "\n",
    "matching_score_real = 0\n",
    "matching_score_pred = 0\n",
    "\n",
    "for i,aist_batch in enumerate(tqdm(aist_loader)):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    mot_len = int(aist_batch[\"motion_lengths\"][0])\n",
    "#     print(mot_len)\n",
    "    motion_name = aist_batch[\"names\"][0]\n",
    "    \n",
    "    if len(music_annotation_list)>40:\n",
    "        break\n",
    "\n",
    "    if mot_len < seq_len:\n",
    "        continue\n",
    "\n",
    "    bs, seq = aist_batch[\"motion\"].shape[0], aist_batch[\"motion\"].shape[1]\n",
    "\n",
    "    music_name = motion_name.split('_')[-2]\n",
    "    gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "\n",
    "#     et, em = aist_evaluator.get_co_embeddings(music = aist_batch[\"condition\"] , motions = aist_batch[\"motion\"], m_lens = aist_batch[\"motion_lengths\"])\n",
    "\n",
    "    et, em = aist_evaluator.get_co_embeddings(music = aist_batch[\"condition\"] ,\n",
    "                                            motions = aist_batch[\"motion\"],\n",
    "                                            m_lens = torch.Tensor([seq_len]) )\n",
    "    \n",
    "    while gen_motion_indices.shape[1]<=seq_len:\n",
    "        gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices.cuda(),\\\n",
    "                                                    seq_len=seq_len , \\\n",
    "                                                    context = aist_batch[\"condition\"].cuda(), \\\n",
    "                                                    context_mask=torch.ones((1 ,aist_batch[\"condition\"].shape[1]) , dtype = torch.bool).cuda()\n",
    "                                                    )\n",
    "\n",
    "\n",
    "    out_motion = torch.zeros((aist_batch[\"motion\"].shape[0] ,gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "    for i in range(0 , seq_len, 200):\n",
    "        quant , out_motion_= vqvae_model.decode(gen_motion_indices[:,i:i+200])\n",
    "        out_motion[:,i:i+200] = out_motion_\n",
    "        \n",
    "\n",
    "#     et_pred, em_pred = aist_evaluator.get_co_embeddings(\n",
    "#                                                 music = aist_batch[\"condition\"]  , \\\n",
    "#                                                 motions = out_motion[:,1:int(mot_len)+1], \\\n",
    "#                                                 m_lens = aist_batch[\"motion_lengths\"])\n",
    "\n",
    "    et_pred, em_pred = aist_evaluator.get_co_embeddings(music = aist_batch[\"condition\"] , \\\n",
    "                                            motions =out_motion[:,1:int(seq_len) + 1], \\\n",
    "                                            m_lens = torch.Tensor([seq_len]))\n",
    "\n",
    "\n",
    "    motion_pred_list.append(em_pred)\n",
    "    motion_annotation_list.append(em)\n",
    "\n",
    "    music_pred_list.append(et_pred)\n",
    "    music_annotation_list.append(et)\n",
    "\n",
    "\n",
    "\n",
    "    nb_sample += bs\n",
    "\n",
    "print(nb_sample)\n",
    "\n",
    "\n",
    "motion_annotation_np = torch.cat(motion_annotation_list, dim=0).cpu().numpy()\n",
    "motion_pred_np = torch.cat(motion_pred_list, dim=0).cpu().numpy()\n",
    "\n",
    "music_annotation_np = torch.cat(motion_annotation_list, dim=0).cpu().numpy()\n",
    "music_pred_np = torch.cat(motion_pred_list, dim=0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa76652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 401, 263])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "83e2f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 174, 128])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aist_batch[\"condition\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8bc7c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "motion_annotation_np = torch.cat(motion_annotation_list, dim=0).cpu().numpy()\n",
    "motion_pred_np = torch.cat(motion_pred_list, dim=0).cpu().numpy()\n",
    "\n",
    "music_annotation_np = torch.cat(motion_annotation_list, dim=0).cpu().numpy()\n",
    "music_pred_np = torch.cat(motion_pred_list, dim=0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8839edcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6694914762965667"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_mu, gt_cov  = calculate_activation_statistics(motion_annotation_np)\n",
    "mu, cov= calculate_activation_statistics(motion_pred_np)\n",
    "calculate_frechet_distance(gt_mu, gt_cov, mu, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a02f9d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3413532 1.2625911\n"
     ]
    }
   ],
   "source": [
    "diversity_real = calculate_diversity(motion_annotation_np, 100 if nb_sample > 100 else 30)\n",
    "diversity = calculate_diversity(motion_pred_np, 100 if nb_sample > 100 else 30)\n",
    "print(diversity_real , diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b217ad6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6c491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b00d0af",
   "metadata": {},
   "source": [
    "## AICHOREO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b24e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "from utils.aist_metrics.calculate_fid_scores import calculate_avg_distance, extract_feature,calculate_frechet_feature_distance,calculate_frechet_distance\n",
    "from utils.aist_metrics.features import kinetic,manual\n",
    "from utils.aist_metrics.calculate_beat_scores import motion_peak_onehot,alignment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7a8b38aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:47<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  7.528682831845714 Diversity_k: 10.279027991012589\n",
      "FID_g:  7.848392292979781 Diversity_g: 7.421904608008726\n",
      "\n",
      "Beat score on real data: 0.310\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_fid_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f79ffd4f6e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mbest_fid_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFID_k\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFID_k\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_fid_k\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_fid_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mbest_fid_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFID_g\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFID_g\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_fid_g\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_fid_g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mbest_div_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDist_k\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDist_k\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_div_k\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_div_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_fid_k' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_features = {\"kinetic\": [], \"manual\": []}\n",
    "real_features = {\"kinetic\": [], \"manual\": []}\n",
    "\n",
    "mean = aist_loader.dataset.mean\n",
    "std = aist_loader.dataset.std\n",
    "\n",
    "beat_scores_real = []\n",
    "beat_scores_pred = []\n",
    "\n",
    "real_pfc = []\n",
    "pred_pfc = []\n",
    "\n",
    "seq_len =800\n",
    "\n",
    "audio_dir = audio_encoding_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "audio_feature_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/audio_features/\"\n",
    "\n",
    "\n",
    "# smpl_motions_aist = glob(\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/*.npy\")\n",
    "# for i in glob(\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/hml/*.npy\"):\n",
    "#     smpl_motion = np.load(i)[120: , 6:]\n",
    "# #     print(smpl_motion.shape)\n",
    "#     seq_name = os.path.basename(i).split(\".\")[0]\n",
    "#     smpl_motions_aist.append({\"motion\":smpl_motion , \"name\" : seq_name })\n",
    "\n",
    "\n",
    "\n",
    "for i,path in enumerate(tqdm(smpl_motions_aist)):\n",
    "    \n",
    "    motion_name = os.path.basename(path)\n",
    "    \n",
    "    gt_motion = torch.Tensor(np.load(f\"/srv/scratch/sanisetty3/music_motion/AIST/new_joint_vecs/{motion_name[:-9]}.npy\")[None,...])\n",
    "#     print(gt_motion.shape)\n",
    "    out_motion = torch.Tensor(np.load(f\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/hml/{motion_name}\")[None,...])\n",
    "#     print(out_motion.shape)\n",
    "\n",
    "    keypoints3d_gt = recover_from_ric(gt_motion[0,:seq_len] , 22).detach().cpu().numpy()\n",
    "    keypoints3d_pred = recover_from_ric(out_motion[0,:seq_len] , 22).detach().cpu().numpy()\n",
    "\n",
    "    real_features[\"kinetic\"].append(extract_feature(keypoints3d_gt, \"kinetic\"))\n",
    "    real_features[\"manual\"].append(extract_feature(keypoints3d_gt, \"manual\"))\n",
    "\n",
    "    result_features[\"kinetic\"].append(extract_feature(keypoints3d_pred, \"kinetic\"))\n",
    "    result_features[\"manual\"].append(extract_feature(keypoints3d_pred, \"manual\"))\n",
    "\n",
    "#     real_pfc.append(calc_physical_score(keypoints3d_gt))\n",
    "#     pred_pfc.append(calc_physical_score(keypoints3d_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    motion_beats = motion_peak_onehot(keypoints3d_gt[:seq_len])\n",
    "    # get real data music beats\n",
    "    audio_name = motion_name.split(\"_\")[-3]\n",
    "\n",
    "    audio_feature = np.load(os.path.join(audio_feature_dir, f\"{audio_name}.npy\"))\n",
    "    audio_beats = audio_feature[:seq_len, -1] # last dim is the music beats\n",
    "    # get beat alignment scores\n",
    "    beat_score = alignment_score(audio_beats, motion_beats, sigma=1)\n",
    "    beat_scores_real.append(beat_score)\n",
    "\n",
    "\n",
    "    motion_beats = motion_peak_onehot(keypoints3d_pred[:seq_len])\n",
    "    beat_score_pred = alignment_score(audio_beats, motion_beats, sigma=1)\n",
    "    beat_scores_pred.append(beat_score_pred)\n",
    "\n",
    "\n",
    "FID_k, Dist_k = calculate_frechet_feature_distance(real_features[\"kinetic\"], result_features[\"kinetic\"])\n",
    "FID_g, Dist_g = calculate_frechet_feature_distance(real_features[\"manual\"], result_features[\"manual\"])\n",
    "\n",
    "\n",
    "print(\"FID_k: \",FID_k,\"Diversity_k:\",Dist_k)\n",
    "print(\"FID_g: \",FID_g,\"Diversity_g:\",Dist_g)\n",
    "\n",
    "# print (\"\\PFC score on real data: %.3f\\n\" % (np.mean(real_pfc)))\n",
    "# print (\"\\PFC score on generated data: %.3f\\n\" % (np.mean(pred_pfc)))\n",
    "\n",
    "\n",
    "print (\"\\nBeat score on real data: %.3f\\n\" % (np.mean(beat_scores_real)))\n",
    "print (\"\\nBeat score on generated data: %.3f\\n\" % (np.mean(beat_scores_pred)))\n",
    "\n",
    "\n",
    "\n",
    "best_fid_k = FID_k if FID_k < best_fid_k else best_fid_k\n",
    "best_fid_g = FID_g if FID_g < best_fid_g else best_fid_g\n",
    "best_div_k = Dist_k if Dist_k > best_div_k else best_div_k\n",
    "best_div_g = Dist_g if Dist_g > best_div_g else best_div_g\n",
    "\n",
    "best_beat_align = np.mean(beat_scores_real) if np.mean(beat_scores_real) > best_beat_align else best_beat_align \n",
    "\n",
    "\n",
    "\n",
    "# return best_fid_k, best_fid_g,best_div_k,best_div_g,best_beat_align , np.mean(real_pfc), np.mean(pred_pfc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05033cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf05ef6d",
   "metadata": {},
   "source": [
    "## Transformed HML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cdeed768",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints3d_hml = np.load(\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/keypoints3D_hml60.npy\").reshape(-1,22,3)\n",
    "keypoints3d_aist = np.load(\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/keypoints3D_aist.npy\")[:52756,:22,:]\n",
    "\n",
    "from pycpd import RigidRegistration, DeformableRegistration\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4d955506",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RigidRegistration(X=keypoints3d_aist[:100].reshape(-1,3), Y=keypoints3d_hml[:100].reshape(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "44188cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TY, (s_reg, R_reg, t_reg) = reg.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "40f10e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.646927100911472e-05"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TY - keypoints3d_aist[:100].reshape(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8c022950",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points_to_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-56abaccc52c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_point_cloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoints_to_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'points_to_transform' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5d0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f12d8272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1387.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "val_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a1f10c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in aist_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "16a7d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints3d_gt = recover_from_ric(batch[\"motion\"][0,:100] , 22).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2fcf3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/paper_renders/smpl/keypoints3d_gt.npy\" , reg.transform_point_cloud(Y=keypoints3d_gt.reshape(-1,3)).reshape(-1,22,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cdf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5d88a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 45.42it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.73it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.42it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.57it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.31it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.58it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.29it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.51it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.41it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.47it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.03it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.45it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.43it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.43it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.43it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.43it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.32it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.39it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.39it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.35it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.44it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.38it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.40it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.36it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.37it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.30it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.43it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.33it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.37it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.38it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.29it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.41it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.35it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.39it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.37it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.47it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.41it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.44it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.35it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.47it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.49it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.35it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.48it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.33it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.26it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.38it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.37it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.45it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.39it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.46it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.40it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.48it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.35it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.47it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.35it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.40it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.33it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.44it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.29it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.39it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.38it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.41it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.40it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.34it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.32it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.47it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.46it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.42it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.42it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.36it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.24it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.38it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.47it/s]\n",
      "100%|██████████| 400/400 [00:10<00:00, 39.37it/s]\n",
      "100%|██████████| 40/40 [13:24<00:00, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  6.9577679600177476 Diversity_k: 10.06756729009824\n",
      "FID_g:  11.167501952145543 Diversity_g: 7.1934799310488575\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_fid_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-b2fbd4f6fb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBeat score on generated data: %.3f\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeat_scores_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mbest_fid_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFID_k\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFID_k\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_fid_k\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_fid_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mbest_fid_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFID_g\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFID_g\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_fid_g\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_fid_g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mbest_div_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDist_k\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDist_k\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_div_k\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_div_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_fid_k' is not defined"
     ]
    }
   ],
   "source": [
    "result_features = {\"kinetic\": [], \"manual\": []}\n",
    "real_features = {\"kinetic\": [], \"manual\": []}\n",
    "\n",
    "mean = val_loader.dataset.mean\n",
    "std = val_loader.dataset.std\n",
    "\n",
    "beat_scores_real = []\n",
    "beat_scores_pred = []\n",
    "\n",
    "for i,aist_batch in enumerate(tqdm(val_loader)):\n",
    "\n",
    "\n",
    "    mot_len = aist_batch[\"motion_lengths\"][0]\n",
    "    motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "    music_name = motion_name.split('_')[-2]\n",
    "    music_encoding=  np.load(os.path.join(audio_encoding_dir , music_name + \".npy\"))\n",
    "\n",
    "    gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "\n",
    "    while gen_motion_indices.shape[1]<=seq_len:\n",
    "\n",
    "       \n",
    "        gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices.cuda(),\\\n",
    "                                                    seq_len=400 , \\\n",
    "                                                    context = torch.Tensor(music_encoding)[None,...].cuda(), \\\n",
    "                                                    context_mask=torch.ones((1 ,music_encoding.shape[0]) , dtype = torch.bool).cuda(),\\\n",
    "                                                    )\n",
    "\n",
    "        gen_motion_indices = gen_motion_indices[gen_motion_indices<1024][None,...]\n",
    "\n",
    "    try:\n",
    "        out_motion = torch.zeros((aist_batch[\"motion\"].shape[0] ,gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "        for i in range(0 , seq_len, 200):\n",
    "            quant , out_motion_= vqvae_model.decode(gen_motion_indices[:,i:i+200])\n",
    "            out_motion[:,i:i+200] = out_motion_\n",
    "\n",
    "        # quant , out_motion = vqvae_model.module.decode(gen_motion_indices[:,:mot_len])\n",
    "    except:\n",
    "        # quant , out_motion = vqvae_model.decode(gen_motion_indices[:,:mot_len])\n",
    "        out_motion = torch.zeros((aist_batch[\"motion\"].shape[0] ,gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "        for i in range(0 , seq_len, 200):\n",
    "            quant , out_motion_= vqvae_model.decode(gen_motion_indices[:,i:i+200])\n",
    "            out_motion[:,i:i+200] = out_motion_\n",
    "\n",
    "\n",
    "    keypoints3d_gt = recover_from_ric(aist_batch[\"motion\"][0,:mot_len] , 22).detach().cpu().numpy()\n",
    "    keypoints3d_gt = reg.transform_point_cloud(Y=keypoints3d_gt.reshape(-1,3)).reshape(-1,22,3)\n",
    "    \n",
    "    \n",
    "    keypoints3d_pred = recover_from_ric(out_motion[0,:mot_len] , 22).detach().cpu().numpy()\n",
    "    keypoints3d_pred = reg.transform_point_cloud(Y=keypoints3d_pred.reshape(-1,3)).reshape(-1,22,3)\n",
    "    \n",
    "    \n",
    "    real_features[\"kinetic\"].append(extract_feature(keypoints3d_gt, \"kinetic\"))\n",
    "    real_features[\"manual\"].append(extract_feature(keypoints3d_gt, \"manual\"))\n",
    "\n",
    "    result_features[\"kinetic\"].append(extract_feature(keypoints3d_pred, \"kinetic\"))\n",
    "    result_features[\"manual\"].append(extract_feature(keypoints3d_pred, \"manual\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    motion_beats = motion_peak_onehot(keypoints3d_gt[:mot_len])\n",
    "    # get real data music beats\n",
    "    audio_name = motion_name.split(\"_\")[-2]\n",
    "\n",
    "    audio_feature = np.load(os.path.join(audio_feature_dir, f\"{audio_name}.npy\"))\n",
    "    audio_beats = audio_feature[:mot_len, -1] # last dim is the music beats\n",
    "    # get beat alignment scores\n",
    "    beat_score = alignment_score(audio_beats, motion_beats, sigma=1)\n",
    "    beat_scores_real.append(beat_score)\n",
    "\n",
    "\n",
    "    motion_beats = motion_peak_onehot(keypoints3d_pred[:mot_len])\n",
    "    beat_score_pred = alignment_score(audio_beats, motion_beats, sigma=1)\n",
    "    beat_scores_pred.append(beat_score_pred)\n",
    "\n",
    "\n",
    "FID_k, Dist_k = calculate_frechet_feature_distance(real_features[\"kinetic\"], result_features[\"kinetic\"])\n",
    "FID_g, Dist_g = calculate_frechet_feature_distance(real_features[\"manual\"], result_features[\"manual\"])\n",
    "\n",
    "\n",
    "print(\"FID_k: \",FID_k,\"Diversity_k:\",Dist_k)\n",
    "print(\"FID_g: \",FID_g,\"Diversity_g:\",Dist_g)\n",
    "\n",
    "\n",
    "print (\"\\nBeat score on real data: %.3f\\n\" % (np.mean(beat_scores_real)))\n",
    "print (\"\\nBeat score on generated data: %.3f\\n\" % (np.mean(beat_scores_pred)))\n",
    "\n",
    "best_fid_k = FID_k if FID_k < best_fid_k else best_fid_k\n",
    "best_fid_g = FID_g if FID_g < best_fid_g else best_fid_g\n",
    "best_div_k = Dist_k if Dist_k > best_div_k else best_div_k\n",
    "best_div_g = Dist_g if Dist_g > best_div_g else best_div_g\n",
    "\n",
    "best_beat_align = np.mean(beat_scores_real) if np.mean(beat_scores_real) > best_beat_align else best_beat_align \n",
    "\n",
    "\n",
    "\n",
    "return best_fid_k, best_fid_g,best_div_k,best_div_g,best_beat_align\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9c831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a03868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce64cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56400896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad058c8",
   "metadata": {},
   "source": [
    "## Sinusoidal pos emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1347a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f0b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2797d1",
   "metadata": {},
   "source": [
    "FID_k:  3.8717503038434415 Diversity_k: 10.580599220288105\n",
    "FID_g:  14.323117971786502 Diversity_g: 7.208645957555526\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8adb76",
   "metadata": {},
   "source": [
    "### Albi\n",
    "\n",
    "FID_k:  5.974822501678858 Diversity_k: 9.894211104435799\n",
    "FID_g:  10.945797702730552 Diversity_g: 7.33098736114991\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ea200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c4a7a42",
   "metadata": {},
   "source": [
    "## Style motion generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f59388c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_generative_style, evaluate_music_motion_generative_style2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5618bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3d92e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=torch.device('cuda'), jit=False)  # Must set jit=False for training\n",
    "clip_model.eval()\n",
    "for p in clip_model.parameters():\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8fe653da",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_style = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_style/var_len_768_768_aist_style.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3341b8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([95000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(encodec_style)\n",
    "\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"{os.path.dirname(encodec_style)}/trans_motion.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "edcac810",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_music_motion_generative_style' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-e4704d46183b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_music_motion_generative_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maist_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvqvae_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvqvae_model\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_music_motion_generative_style' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_music_motion_generative_style(aist_loader , vqvae_model= vqvae_model ,net = trans_model,clip_model=clip_model,seq_len = 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "385cb921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:22<00:00, 84.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49d861f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:21<00:00, 37.43it/s]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.46it/s]]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.45it/s]t]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.42it/s]t]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.37it/s]t]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.33it/s]t]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.35it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.35it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.34it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.25it/s]]  \n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.23it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.33it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.29it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.32it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.26it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.31it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.26it/s]]  \n",
      "100%|██████████| 800/800 [00:21<00:00, 37.30it/s]it]\n",
      "100%|██████████| 800/800 [00:21<00:00, 37.27it/s]it]\n",
      " 35%|███▌      | 673/1910 [18:37<34:14,  1.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  3.522845989252062 Diversity_k: 10.215643210963504\n",
      "FID_g:  8.57888238870914 Diversity_g: 7.215440534382331\n",
      "\n",
      "Beat score on real data: 0.172\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.522845989252062,\n",
       " 8.57888238870914,\n",
       " 10.215643210963504,\n",
       " 7.215440534382331,\n",
       " 0.1715415597282555)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_generative_style2(aist_loader , vqvae_model= vqvae_model ,net = trans_model,clip_model=clip_model,seq_len = 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "08c3ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25995348837209303"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.243*0.184 / 0.172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35535c27",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b9964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_encoding_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "\n",
    "genre_dict = {\n",
    "\"mBR\" : \"Break\",\n",
    "\"mPO\" : \"Pop\",\n",
    "\"mLO\" : \"Lock\",\n",
    "\"mMH\" : \"Middle Hip-hop\",\n",
    "\"mLH\" : \"LA style Hip-hop\",\n",
    "\"mHO\" : \"House\",    \n",
    "\"mWA\" : \"Waack\",\n",
    "\"mKR\" : \"Krump\",\n",
    "\"mJS\" : \"Street Jazz\",\n",
    "\"mJB\" : \"Ballet Jazz\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4899a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7de8c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballet Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i,aist_batch in enumerate(tqdm(aist_loader)):\n",
    "    break\n",
    "motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "music_name = motion_name.split('_')[-2]\n",
    "music_encoding=  np.load(os.path.join(audio_encoding_dir , music_name + \".npy\"))\n",
    "\n",
    "print(genre_dict.get(music_name[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb7e9dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballet Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 56.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mot_len = aist_batch[\"motion_lengths\"][0]\n",
    "motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "music_name = motion_name.split('_')[-2]\n",
    "music_encoding=  np.load(os.path.join(audio_encoding_dir , music_name + \".npy\"))\n",
    "\n",
    "print(genre_dict.get(music_name[:3]))\n",
    "\n",
    "genre = (genre_dict.get(music_name[:3])) if style is None else style\n",
    "\n",
    "text = clip.tokenize([genre], truncate=True).cuda()\n",
    "style_embeddings = clip_model.encode_text(text).cpu().float().reshape(-1) if clip_model is not None else None\n",
    "gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices.cuda(),\\\n",
    "                                        seq_len=400 , \\\n",
    "                                        context = torch.Tensor(music_encoding)[None,...].cuda(), \\\n",
    "                                        context_mask=torch.ones((1 ,music_encoding.shape[0]) , dtype = torch.bool).cuda(),\\\n",
    "                                        style_context = torch.Tensor(style_embeddings.reshape(-1))[None,...].cuda(),\n",
    "                                        )\n",
    "gen_motion_indices = gen_motion_indices[gen_motion_indices<1024][None,...]\n",
    "\n",
    "quant , out_motion = vqvae_model.decode(gen_motion_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbb48571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 147, 263])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73af7f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slow'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0df6c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"style_gt\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87719b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[:,:mot_len].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"style_none\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/style/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32409bf",
   "metadata": {},
   "source": [
    "### Music VQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d272e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_path_mix = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/checkpoints/vqvae_motion.295000.pt\"\n",
    "load_path_hml = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768/vqvae_motion.pt\"\n",
    "load_path_aist = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_aist/vqvae_motion.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9109ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec336a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from utils.eval_music import evaluate_music_motion_vqvae\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "load_path = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570c7d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"{load_path_mix}\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e0e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ead9dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1496.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9b4276",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained only t2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  3.2996737750179364 Diversity_k: 10.26604298215646\n",
      "FID_g:  10.78302279919913 Diversity_g: 7.181474344852643\n",
      "FID_k_real:  -7.86550347697812e-06 Diversity_k_real: 10.195780532558759\n",
      "FID_g_real:  -1.9184653865522705e-13 Diversity_g_real: 7.348854861503992\n",
      "\n",
      "Beat score on real data: 0.245\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.2996737750179364,\n",
       " 10.78302279919913,\n",
       " 10.26604298215646,\n",
       " 7.181474344852643,\n",
       " 0.24494051462936942)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"pretrained only t2m\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cee809d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(\"pretrained mix\")\n",
    "# best_fid_k = []\n",
    "# best_fid_g = []\n",
    "# best_div_k = []\n",
    "# best_div_g = []\n",
    "# best_beat_align = []\n",
    "\n",
    "# for i in range(20):\n",
    "\n",
    "#     a,b,c,d,e = evaluate_music_motion_vqvae(aist_loader,vqvae_model)\n",
    "#     best_fid_k.append(a)\n",
    "#     best_fid_g.append(b)\n",
    "#     best_div_k.append(c)\n",
    "#     best_div_g.append(d)\n",
    "#     best_beat_align.append(e)\n",
    "\n",
    "    \n",
    "# print(\"best_fid_k\" , np.mean(best_fid_k))\n",
    "# print(\"best_fid_g\" , np.mean(best_fid_g))\n",
    "# print(\"best_div_k\" , np.mean(best_div_k))\n",
    "# print(\"best_div_g\" , np.mean(best_div_g))\n",
    "# print(\"best_beat_align\" , np.mean(best_beat_align))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905d603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:39<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  2.635362356342995 Diversity_k: 10.163608189500295\n",
      "FID_g:  7.295345718653849 Diversity_g: 7.234946262225127\n",
      "FID_k_real:  -7.757004908626186e-06 Diversity_k_real: 10.205963216454554\n",
      "FID_g_real:  -1.903529778246593e-09 Diversity_g_real: 7.344472836225461\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.635362356342995,\n",
       " 7.295345718653849,\n",
       " 10.163608189500295,\n",
       " 7.234946262225127,\n",
       " 0.244130060202235)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"mix\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5165ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635881b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "727139c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained only t2m, finetuned only aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:01<00:37,  1.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-88106f13813e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pretrained only t2m, finetuned only aist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_music_motion_vqvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maist_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvqvae_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/coc/scratch/sanisetty3/music_motion/motion_vqvae/utils/eval_music.py\u001b[0m in \u001b[0;36mevaluate_music_motion_vqvae\u001b[0;34m(val_loader, net, audio_feature_dir, best_fid_k, best_fid_g, best_div_k, best_div_g, best_beat_align)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mkeypoints3d_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecover_from_ric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_motion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmot_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mreal_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mreal_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"manual\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"manual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/coc/scratch/sanisetty3/music_motion/motion_vqvae/utils/aist_metrics/calculate_fid_scores.py\u001b[0m in \u001b[0;36mextract_feature\u001b[0;34m(keypoints3d, mode)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_kinetic_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"manual\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_manual_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/aist_plusplus/features/kinetic.py\u001b[0m in \u001b[0;36mextract_kinetic_features\u001b[0;34m(positions)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_kinetic_energy_horizontal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_kinetic_energy_vertical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_energy_expenditure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             ]\n\u001b[1;32m     47\u001b[0m         )\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/aist_plusplus/features/kinetic.py\u001b[0m in \u001b[0;36maverage_energy_expenditure\u001b[0;34m(self, joint)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             val += feat_utils.calc_average_acceleration(\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliding_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             )\n\u001b[1;32m    110\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/aist_plusplus/features/utils.py\u001b[0m in \u001b[0;36mcalc_average_acceleration\u001b[0;34m(positions, i, joint_idx, sliding_window, frame_time)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjoint_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mframe_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         )\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0maverage_acceleration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mframe_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mcurrent_window\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_acceleration\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcurrent_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"pretrained only t2m, finetuned only aist\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26b752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b755169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f091bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [29:56<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.010750366559051372 Diversity_k: 9.172959109891172\n",
      "FID_g:  1.2350136226828567 Diversity_g: 7.381343867734843\n",
      "\n",
      "Beat score on real data: 0.249\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.010750366559051372,\n",
       " 1.2350136226828567,\n",
       " 9.172959109891172,\n",
       " 7.381343867734843,\n",
       " 0.24940255611332512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Mixture\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6807ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cbf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "929e37dd",
   "metadata": {},
   "source": [
    "## Generating token dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334185f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.05, 135.15, 204.0, 127.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.11*255, 0.53*255, 0.8*255, 0.5*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d06f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039cc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cda3fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:01<00:00, 1244.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "128f1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [01:47<00:00, 17.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(aist_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "#         ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "        inds = []\n",
    "        for i in range(0 , n, 200):\n",
    "            ii = vqvae_model.encode(batch[\"motion\"][:,i:i+200].cuda())\n",
    "            inds.append(ii[0])\n",
    "#             print(ii.shape)\n",
    "        \n",
    "        ind = torch.concatenate(inds)[None,...]\n",
    "        \n",
    "#     print(ind.shape)\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/AIST/joint_indices\" , name+\".npy\"),ind.cpu().numpy()[0])\n",
    "        \n",
    "#         quant , out_motion = vqvae_model.decode(ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1e7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eefd3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_list = glob(\"/srv/scratch/sanisetty3/music_motion/AIST/joint_indices/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f23214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(mot_list[0]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a68d41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "for i in mot_list:\n",
    "    lens.append(np.load(i).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef30e7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa63c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55b6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23384/23384 [08:53<00:00, 43.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 23384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hlm_ds = VQFullMotionDataset(\"t2m\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/\" , window_size = -1)\n",
    "hlm_loader = DATALoader(hlm_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d262e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914ddffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23384 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(hlm_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "429fe4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 M003397\n"
     ]
    }
   ],
   "source": [
    "n = int(batch[\"motion_lengths\"])\n",
    "name = str(batch[\"names\"][0])\n",
    "print(n,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9daa0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(batch[\"motion\"].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4c5d478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 199])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06dcf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23384 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices/007648.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7e92969d732f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices/007648.npy'"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(hlm_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "        #ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "#         out_motion = torch.zeros((batch[\"motion\"].shape[0] ,gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "        inds = []\n",
    "        for i in range(0 , n, 200):\n",
    "            inds.append(vqvae_model.encode(batch[\"motion\"].cuda()))\n",
    "        \n",
    "        ind = torch.stack(inds)\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices\" , name+\".npy\"), ind.cpu().numpy()[0])\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14428964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507abd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(batch[\"motion\"][0:1].detach().cpu(),mean = hlm_ds.mean , std = hlm_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc99328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb20b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a0b19e9",
   "metadata": {},
   "source": [
    "## T2M Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8f912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils_model as utils_model\n",
    "from core.datasets import dataset_TM_eval\n",
    "import utils.eval_trans as eval_trans\n",
    "from core.models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "from utils.eval_trans import evaluation_vqvae_loss,evaluation_vqvae\n",
    "from utils.eval_trans import calculate_R_precision,calculate_activation_statistics,calculate_diversity,calculate_frechet_distance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdecf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1460 [00:00<00:43, 33.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1460/1460 [00:51<00:00, 28.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530 1530\n",
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_vectorizer = WordVectorizer('/srv/scratch/sanisetty3/music_motion/T2M-GPT/glove', 'our_vab')\n",
    "eval_wrapper = EvaluatorModelWrapper(cfg.eval_model)\n",
    "tm_eval = dataset_TM_eval.DATALoader(\"t2m\", False, 20, w_vectorizer, unit_length=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84b0abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tm_eval:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d5f5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings, pos_one_hots, caption, sent_len, motion, m_length, token, name = batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15a30e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22, 22, 21, 19, 17, 17, 15, 15, 15, 14, 13, 12, 12, 11, 10, 10,  8,\n",
       "         8,  7])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d116b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 22, 300])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shapea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646f4266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([275000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "load_path = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_aist/vqvae_motion.pt\"\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"{load_path}\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253031f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75682d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:43<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0668, Diversity Real. 9.5584, Diversity. 9.9187, R_precision_real. [0.60193966 0.78189655 0.86810345], R_precision. [0.59439655 0.77801724 0.85991379], matching_score_real. 2.9862875124503825, matching_score_pred. 3.028119134902954\n"
     ]
    }
   ],
   "source": [
    "### Pretrained on t2m only\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1454baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained on t2m only and finetuned on aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:43<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 3.2204, Diversity Real. 9.3818, Diversity. 7.4288, R_precision_real. [0.59698276 0.78728448 0.86551724], R_precision. [0.43512931 0.64073276 0.75625   ], matching_score_real. 2.9870332890543443, matching_score_pred. 4.043809700012207\n"
     ]
    }
   ],
   "source": [
    "print(\"pretrained on t2m only and finetuned on aist\")\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701a9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad4ce29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:42<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0637, Diversity Real. 9.4620, Diversity. 9.4266, R_precision_real. [0.61616379 0.79482759 0.86982759], R_precision. [0.60172414 0.78405172 0.86077586], matching_score_real. 2.9635313979510602, matching_score_pred. 3.0240239735307366\n"
     ]
    }
   ],
   "source": [
    "## Pretrained on a mix of aist and t2m\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fe5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4defa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1221bf6",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c048d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from render_final import render, saveSMPL\n",
    "from core.datasets.vqa_motion_dataset import TransMotionDatasetConditionalFull\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b9bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions_list = glob(\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/hml/*.npy\" , recursive=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e3d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions_list = glob(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/generator/var_len/trans_768_768_albi_aist/*.npy\" , recursive=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01b3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.load(\"/srv/scratch/sanisetty3/music_motion/AIST/Std.npy\")\n",
    "mean = np.load(\"/srv/scratch/sanisetty3/music_motion/AIST/Mean.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae7196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cbc0150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 401, 263])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.load(motions_list[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a49e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7fac409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mWA3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/scratch/sanisetty3/music_motion/motion_vqvae/render_final.py:204: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vertices, rotations, global_orient, out, x_translations = rot2xyz(torch.tensor(motion_tensor).clone(), mask=None,\n",
      "  2%|▏         | 1/60 [02:46<2:43:58, 166.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mWA4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/60 [06:02<2:49:36, 175.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mHO4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 3/60 [08:53<2:45:30, 174.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mHO3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/60 [11:29<2:37:20, 168.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mMH3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 5/60 [14:22<2:35:51, 170.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJB4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 6/60 [17:19<2:34:48, 172.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mPO3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 7/60 [19:53<2:27:19, 166.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mPO4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 8/60 [22:52<2:27:39, 170.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJB3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 9/60 [25:18<2:18:29, 162.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mMH4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 10/60 [28:12<2:18:42, 166.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJS4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 11/60 [30:44<2:12:21, 162.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mBR0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 12/60 [33:24<2:09:04, 161.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJS3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 13/60 [36:11<2:07:38, 162.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLH3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 14/60 [38:52<2:04:34, 162.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLH4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 15/60 [40:55<1:52:59, 150.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mKR2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 16/60 [43:19<1:49:06, 148.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLO1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 17/60 [45:26<1:41:55, 142.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mKR5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 18/60 [48:14<1:44:56, 149.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mPO5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 19/60 [51:06<1:46:54, 156.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mMH5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 20/60 [54:06<1:48:58, 163.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJB2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 21/60 [56:42<1:44:52, 161.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJB5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 22/60 [59:45<1:46:15, 167.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mMH2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 23/60 [1:02:02<1:37:47, 158.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mPO2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 24/60 [1:04:46<1:36:04, 160.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mHO2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 25/60 [1:07:47<1:37:05, 166.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mHO5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 26/60 [1:11:00<1:38:48, 174.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mWA5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 27/60 [1:13:53<1:35:42, 174.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mWA2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 28/60 [1:16:21<1:28:34, 166.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLO0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 29/60 [1:19:11<1:26:32, 167.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mKR4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 30/60 [1:21:37<1:20:27, 160.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mKR3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 31/60 [1:24:28<1:19:12, 163.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLH5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 32/60 [1:27:17<1:17:16, 165.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLH2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 33/60 [1:30:05<1:14:47, 166.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mBR1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 34/60 [1:32:29<1:09:05, 159.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJS2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 35/60 [1:35:21<1:07:59, 163.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJS5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 36/60 [1:38:16<1:06:43, 166.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLO4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 37/60 [1:41:13<1:05:10, 170.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mKR0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 38/60 [1:44:13<1:03:23, 172.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLO3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 39/60 [1:46:39<57:41, 164.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLH1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 40/60 [1:49:16<54:12, 162.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mBR5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 41/60 [1:52:10<52:34, 166.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJS1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 42/60 [1:55:01<50:15, 167.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mBR2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 43/60 [1:57:49<47:28, 167.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mMH1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 44/60 [2:00:50<45:43, 171.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mPO1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 45/60 [2:04:06<44:45, 179.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJB1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 46/60 [2:07:03<41:35, 178.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mHO1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 47/60 [2:09:42<37:22, 172.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mWA1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 48/60 [2:12:37<34:40, 173.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJS0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 49/60 [2:15:44<32:32, 177.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mBR3\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 50/60 [2:18:16<28:16, 169.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mBR4\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 51/60 [2:20:55<24:59, 166.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLH0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 52/60 [2:23:58<22:50, 171.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLO2\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 53/60 [2:27:17<20:58, 179.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mLO5\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 54/60 [2:30:14<17:53, 178.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mKR1\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 55/60 [2:33:06<14:44, 176.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mWA0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 56/60 [2:36:24<12:12, 183.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mHO0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 57/60 [2:39:20<09:03, 181.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mJB0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 58/60 [2:41:35<05:34, 167.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mMH0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 59/60 [2:44:13<02:44, 164.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n",
      "mPO0\n",
      "cuda:0\n",
      "./body_models/\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "Running SMPLify, it may take a few minutes.\n",
      "torch.Size([1, 25, 6, 401]) dict_keys(['pose', 'betas', 'cam'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [2:46:40<00:00, 166.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6890, 3, 401])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(motions_list):\n",
    "    name =os.path.basename(i).split(\".\")[0]\n",
    "    print(name)\n",
    "    motion = torch.Tensor(np.load(i))\n",
    "    motion_xyz = to_xyz(torch.Tensor(motion) , mean= mean , std = std)\n",
    "    saveSMPL(motion_xyz[0].numpy(), outdir= os.path.join(os.path.dirname(i) , \"SMPL_dict\"), name=name+\"smpl_dict\", pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f0772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b25877",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_dict_list = glob(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/generator/var_len/trans_768_768_albi_aist/SMPL_dict/*pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426116ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_dict = torch.load(smpl_dict_list[0], map_location = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44756691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([401, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_dict[\"global_orient\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a671e32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([401, 23, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_dict[\"rotations\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6631e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = np.concatenate((smpl_dict[\"global_orient\"][:,None,:,:] ,smpl_dict[\"rotations\"] ) , axis = 1).reshape(smpl_dict[\"global_orient\"].shape[0] , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6930c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 401])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_dict[\"x_translations\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4f2d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = smpl_dict[\"x_translations\"][0].cpu().numpy().T\n",
    "trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2003d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b3c9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist = np.concatenate((np.zeros((trans.shape[0] , 6)) , trans , rots) , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91ae6632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 225)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c48ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
