{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcaaaca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d978f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120cfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "import visualize.plot_3d_global as plot_3d\n",
    "from glob import glob\n",
    "def to_xyz(motion, mean ,std , j = 22):\n",
    "    motion_xyz = recover_from_ric(motion.cpu().float()*std+mean, j)\n",
    "    motion_xyz = motion_xyz.reshape(motion.shape[0],-1, j, 3)\n",
    "    return motion_xyz\n",
    "\n",
    "            \n",
    "def sample_render(motion_xyz , name , save_path):\n",
    "    print(f\"render start\")\n",
    "    \n",
    "    gt_pose_vis = plot_3d.draw_to_batch(motion_xyz.numpy(),None, [os.path.join(save_path,name + \".gif\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fb7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7431cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_model = MotionRegressorModel(args = cfg.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b9f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75437290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = MotionCollator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50424dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 60 - 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 37.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = VQVarLenMotionDataset(\"t2m\", split = \"render\" , max_length_seconds = 10, data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D\")\n",
    "train_loader = DATALoader(train_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc774b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQVarLenMotionDataset(\"aist\", split = \"render\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , num_stages = 6 ,min_length_seconds=20, max_length_seconds=30)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32fea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 600\n"
     ]
    }
   ],
   "source": [
    "aist_loader.dataset.set_stage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da01534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 159, 263])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for aist_batch in aist_loader:\n",
    "    break\n",
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99107113",
   "metadata": {},
   "source": [
    "## Trans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e491b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca3b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([195000.])\n"
     ]
    }
   ],
   "source": [
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58013d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b565e8",
   "metadata": {},
   "source": [
    "## Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fb8e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 191])\n"
     ]
    }
   ],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"].cuda())\n",
    "print(ind.shape)\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f010f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.empty(aist_batch[\"motion\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bf733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c188c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"][:,:400].cuda())\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41c3dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant , out_motion = vqvae_model.decode(ind[:,400:].to(torch.long).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5411013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,400:] = out_motion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d67a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_og_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "241a5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion_ind_400\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ebcdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(0,1024,(1,60))\n",
    "quant , out_motion = vqvae_model.decode(indices.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90379db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f95c09",
   "metadata": {},
   "source": [
    "## Music Eval stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df396922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ad8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "from utils.aist_metrics import calculate_fid_scores\n",
    "from utils.aist_metrics.calculate_fid_scores import calculate_avg_distance, extract_feature,calculate_frechet_feature_distance,calculate_frechet_distance\n",
    "from utils.aist_metrics.features import kinetic,manual\n",
    "from utils.aist_metrics.calculate_beat_scores import motion_peak_onehot,alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088f2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import MotionCollatorConditional, TransMotionDatasetConditional,VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14fb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae, evaluate_music_motion_generative,evaluate_music_motion_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24604a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for aist_batch in tqdm(aist_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b85a62",
   "metadata": {},
   "source": [
    "### Const len trained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c1c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([85000.])\n"
     ]
    }
   ],
   "source": [
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/const_len/trans_768_768_aist/vqvae_motion.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ea564d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2763786008230453"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.23/0.243 * 0.292"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365a3a3",
   "metadata": {},
   "source": [
    "## Evaluate Music Motion transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58ec364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/var_len_768_768_aist.yaml\"\n",
    "encodec_sine = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_sine_aist/var_len_768_768_sine_aist.yaml\"\n",
    "librosa = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_35/var_len_768_768_aist_35.yaml\"\n",
    "encodec_prob50 = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_mask_prob50/trans_768_768_albi_aist_mask_prob50.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "518c307d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b89358d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da714b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([145000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "trans_option = \"encodec_sine\"\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(encodec_sine)\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"{os.path.dirname(encodec_sine)}/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcda749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_encoding_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "audio_features_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/audio_features/\"\n",
    "use35 = False\n",
    "if trans_option == \"librosa\":\n",
    "    audio_encoding_dir = audio_features_dir\n",
    "    use35 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40f82831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81752e",
   "metadata": {},
   "source": [
    "## Evaluate Music Motion Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67202e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae, evaluate_music_motion_generative,evaluate_music_motion_generative2,evaluate_music_motion_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06078153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1700.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e41c4914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/400 [00:00<00:06, 64.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:06<00:00, 60.42it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.73it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.44it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.62it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.56it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.68it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.08it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 59.90it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.57it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.68it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.56it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.67it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.68it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.73it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.83it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.69it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.64it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.73it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.77it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.50it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.84it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.92it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.72it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 59.70it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.90it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.70it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.62it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.64it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.86it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.47it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.65it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.47it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.52it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.48it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.95it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.58it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.90it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.55it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 60.52it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 59.43it/s]\n",
      "100%|██████████| 40/40 [05:09<00:00,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  6.403103264620739 Diversity_k: 10.598105856088491\n",
      "FID_g:  11.891712829203748 Diversity_g: 7.263086085441785\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.212\n",
      "\n",
      "\\PFC score on real data: 2.113\n",
      "\n",
      "\\PFC score on generated data: 2.808\n",
      "\n",
      "best_fid_k 6.403103264620739\n",
      "best_fid_g 11.891712829203748\n",
      "best_div_k 10.598105856088491\n",
      "best_div_g 7.263086085441785\n",
      "best_beat_align 0.24413006020223502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.eval_music import evaluate_music_motion_generative\n",
    "print(\"pretrained mix\")\n",
    "best_fid_k = []\n",
    "best_fid_g = []\n",
    "best_div_k = []\n",
    "best_div_g = []\n",
    "best_beat_align = []\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    a,b,c,d,e = evaluate_music_motion_generative(aist_loader , vqvae_model= vqvae_model ,net = trans_model,use35=use35)\n",
    "    best_fid_k.append(a)\n",
    "    best_fid_g.append(b)\n",
    "    best_div_k.append(c)\n",
    "    best_div_g.append(d)\n",
    "    best_beat_align.append(e)\n",
    "\n",
    "    \n",
    "print(\"best_fid_k\" , np.mean(best_fid_k))\n",
    "print(\"best_fid_g\" , np.mean(best_fid_g))\n",
    "print(\"best_div_k\" , np.mean(best_div_k))\n",
    "print(\"best_div_g\" , np.mean(best_div_g))\n",
    "print(\"best_beat_align\" , np.mean(best_beat_align))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_k:  5.848359006888529 Diversity_k: 9.930449794347469\n",
    "FID_g:  10.19790933574938 Diversity_g: 7.301737963236295\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.233\n",
    "\n",
    "\\PFC score on real data: 2.113\n",
    "\n",
    "\\PFC score on generated data: 1.169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58dac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:01<00:00, 1568.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds_train = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader_train = DATALoader(aist_ds_train,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "047322a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/900 [00:00<00:14, 62.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:20<00:00, 42.96it/s]\n",
      "100%|██████████| 900/900 [00:20<00:00, 43.03it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.70it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.74it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.69it/s]it]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.81it/s]it]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.37it/s]]  \n",
      "100%|██████████| 900/900 [00:21<00:00, 42.73it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.74it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.77it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.46it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.69it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.79it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.13it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.60it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.56it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.75it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.85it/s]]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.64it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.51it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.42it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.66it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.72it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.61it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.67it/s]s]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.61it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.68it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.33it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.43it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.21it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.10it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.07it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.13it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.28it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.59it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.57it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.56it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.52it/s]t]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.70it/s]s]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.78it/s]s]\n",
      "100%|██████████| 900/900 [00:21<00:00, 42.53it/s]t]\n",
      " 95%|█████████▌| 1818/1910 [18:01<00:54,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  6.394353653410235 Diversity_k: 10.558077923262992\n",
      "FID_g:  8.632308692625102 Diversity_g: 7.294414699949869\n",
      "\\PFC score on real data: 1.677\n",
      "\n",
      "\\PFC score on generated data: 1.239\n",
      "\n",
      "\n",
      "Beat score on real data: 0.170\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.164\n",
      "\n",
      "best_fid_k 6.394353653410235\n",
      "best_fid_g 8.632308692625102\n",
      "best_div_k 10.558077923262992\n",
      "best_div_g 7.294414699949869\n",
      "best_beat_align 0.17011690074139812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"pretrained mix\")\n",
    "best_fid_k = []\n",
    "best_fid_g = []\n",
    "best_div_k = []\n",
    "best_div_g = []\n",
    "best_beat_align = []\n",
    "seq_len = 900\n",
    "for i in range(1):\n",
    "\n",
    "    a,b,c,d,e,f,g = evaluate_music_motion_generative2(aist_loader_train , vqvae_model= vqvae_model ,net = trans_model, use35 = use35,seq_len = seq_len)\n",
    "    best_fid_k.append(a)\n",
    "    best_fid_g.append(b)\n",
    "    best_div_k.append(c)\n",
    "    best_div_g.append(d)\n",
    "    best_beat_align.append(e)\n",
    "\n",
    "    \n",
    "print(\"best_fid_k\" , np.mean(best_fid_k))\n",
    "print(\"best_fid_g\" , np.mean(best_fid_g))\n",
    "print(\"best_div_k\" , np.mean(best_div_k))\n",
    "print(\"best_div_g\" , np.mean(best_div_g))\n",
    "print(\"best_beat_align\" , np.mean(best_beat_align))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2aeef34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22564285714285715"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.243*0.169 / 0.182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sine 800\n",
    "\n",
    "FID_k:  3.3585897511335645 Diversity_k: 10.084781883693323\n",
    "FID_g:  13.196066750688807 Diversity_g: 7.4867808908950995\n",
    "\\PFC score on real data: 1.910\n",
    "\n",
    "\\PFC score on generated data: 0.598\n",
    "\n",
    "\n",
    "Beat score on real data: 0.180\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602abc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_k:  5.514617609935726 Diversity_k: 10.241459463863839\n",
    "FID_g:  14.856035117858639 Diversity_g: 6.822329583618699\n",
    "\\PFC score on real data: 2.361\n",
    "\n",
    "\\PFC score on generated data: 0.116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad058c8",
   "metadata": {},
   "source": [
    "## Sinusoidal pos emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba703c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f4282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2797d1",
   "metadata": {},
   "source": [
    "FID_k:  3.8717503038434415 Diversity_k: 10.580599220288105\n",
    "FID_g:  14.323117971786502 Diversity_g: 7.208645957555526\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8adb76",
   "metadata": {},
   "source": [
    "### Albi\n",
    "\n",
    "FID_k:  5.974822501678858 Diversity_k: 9.894211104435799\n",
    "FID_g:  10.945797702730552 Diversity_g: 7.33098736114991\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7b0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5191ae35",
   "metadata": {},
   "source": [
    "## Style motion generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efe795e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_generative_style, evaluate_music_motion_generative_style2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c896f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 40.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdda31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=torch.device('cuda'), jit=False)  # Must set jit=False for training\n",
    "clip_model.eval()\n",
    "for p in clip_model.parameters():\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81df18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_style = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_style/var_len_768_768_aist_style.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "210c3d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([70000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(encodec_style)\n",
    "\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"{os.path.dirname(encodec_style)}/trans_motion.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04f69eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:19<00:00, 40.98it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.33it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 40.70it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.77it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.00it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.29it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.86it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.85it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.46it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.29it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.94it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.01it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.38it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.67it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.45it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.13it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 40.22it/s]\n",
      "100%|██████████| 800/800 [00:20<00:00, 39.98it/s]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.99it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.36it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.43it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.56it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.47it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.53it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.01it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.27it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.09it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.02it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.21it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.56it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.95it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.08it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.97it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.24it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.53it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.22it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.19it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.06it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.14it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.56it/s]\n",
      "100%|██████████| 40/40 [13:27<00:00, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  4.266941177652797 Diversity_k: 10.405532233531659\n",
      "FID_g:  12.157996814590398 Diversity_g: 7.164521244856028\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.183\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.266941177652797,\n",
       " 12.157996814590398,\n",
       " 10.405532233531659,\n",
       " 7.164521244856028,\n",
       " 0.24413006020223502)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_generative_style(aist_loader , vqvae_model= vqvae_model ,net = trans_model,clip_model=clip_model,seq_len = 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0691434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:22<00:00, 84.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ff2f40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:18<00:00, 43.81it/s]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.57it/s]]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.35it/s]t]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.43it/s]t]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.57it/s]t]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.32it/s]t]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.45it/s]t]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.29it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.91it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.63it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.25it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.44it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.56it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.40it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.53it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.26it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.35it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.34it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.71it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.66it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.31it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.43it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.32it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.25it/s]]  \n",
      "100%|██████████| 800/800 [00:18<00:00, 43.62it/s]]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.25it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.62it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.74it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.73it/s]]  \n",
      "100%|██████████| 800/800 [00:18<00:00, 43.72it/s]]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.54it/s]]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.55it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.53it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.89it/s]it]\n",
      "100%|██████████| 800/800 [00:19<00:00, 41.51it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 42.32it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.21it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.15it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.29it/s]]  \n",
      "100%|██████████| 800/800 [00:18<00:00, 43.28it/s]it]\n",
      "100%|██████████| 800/800 [00:18<00:00, 43.29it/s]it]\n",
      " 38%|███▊      | 718/1910 [15:45<26:09,  1.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  3.755731383900468 Diversity_k: 10.429904168698846\n",
      "FID_g:  7.751290849860666 Diversity_g: 7.238621158134647\n",
      "\n",
      "Beat score on real data: 0.179\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.755731383900468,\n",
       " 7.751290849860666,\n",
       " 10.429904168698846,\n",
       " 7.238621158134647,\n",
       " 0.17897518020423844)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_generative_style2(aist_loader , vqvae_model= vqvae_model ,net = trans_model,clip_model=clip_model,seq_len = 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2b233f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23621229050279327"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.243*0.174 / 0.179"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d04bf5",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc9b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_encoding_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "\n",
    "genre_dict = {\n",
    "\"mBR\" : \"Break\",\n",
    "\"mPO\" : \"Pop\",\n",
    "\"mLO\" : \"Lock\",\n",
    "\"mMH\" : \"Middle Hip-hop\",\n",
    "\"mLH\" : \"LA style Hip-hop\",\n",
    "\"mHO\" : \"House\",    \n",
    "\"mWA\" : \"Waack\",\n",
    "\"mKR\" : \"Krump\",\n",
    "\"mJS\" : \"Street Jazz\",\n",
    "\"mJB\" : \"Ballet Jazz\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59f7c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71837a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballet Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i,aist_batch in enumerate(tqdm(aist_loader)):\n",
    "    break\n",
    "motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "music_name = motion_name.split('_')[-2]\n",
    "music_encoding=  np.load(os.path.join(audio_encoding_dir , music_name + \".npy\"))\n",
    "\n",
    "print(genre_dict.get(music_name[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4a514d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballet Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 56.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mot_len = aist_batch[\"motion_lengths\"][0]\n",
    "motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "music_name = motion_name.split('_')[-2]\n",
    "music_encoding=  np.load(os.path.join(audio_encoding_dir , music_name + \".npy\"))\n",
    "\n",
    "print(genre_dict.get(music_name[:3]))\n",
    "\n",
    "genre = (genre_dict.get(music_name[:3])) if style is None else style\n",
    "\n",
    "text = clip.tokenize([genre], truncate=True).cuda()\n",
    "style_embeddings = clip_model.encode_text(text).cpu().float().reshape(-1) if clip_model is not None else None\n",
    "gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices.cuda(),\\\n",
    "                                        seq_len=400 , \\\n",
    "                                        context = torch.Tensor(music_encoding)[None,...].cuda(), \\\n",
    "                                        context_mask=torch.ones((1 ,music_encoding.shape[0]) , dtype = torch.bool).cuda(),\\\n",
    "                                        style_context = torch.Tensor(style_embeddings.reshape(-1))[None,...].cuda(),\n",
    "                                        )\n",
    "gen_motion_indices = gen_motion_indices[gen_motion_indices<1024][None,...]\n",
    "\n",
    "quant , out_motion = vqvae_model.decode(gen_motion_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f739c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 147, 263])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2c5ec19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slow'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30014ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"style_gt\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43f2945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[:,:mot_len].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"style_none\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/style/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32409bf",
   "metadata": {},
   "source": [
    "### Music VQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d272e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_path_mix = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/checkpoints/vqvae_motion.295000.pt\"\n",
    "load_path_hml = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768/vqvae_motion.pt\"\n",
    "load_path_aist = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_aist/vqvae_motion.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9109ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec336a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from utils.eval_music import evaluate_music_motion_vqvae\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "load_path = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570c7d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"{load_path_mix}\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e0e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ead9dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1496.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9b4276",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained only t2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  3.2996737750179364 Diversity_k: 10.26604298215646\n",
      "FID_g:  10.78302279919913 Diversity_g: 7.181474344852643\n",
      "FID_k_real:  -7.86550347697812e-06 Diversity_k_real: 10.195780532558759\n",
      "FID_g_real:  -1.9184653865522705e-13 Diversity_g_real: 7.348854861503992\n",
      "\n",
      "Beat score on real data: 0.245\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.2996737750179364,\n",
       " 10.78302279919913,\n",
       " 10.26604298215646,\n",
       " 7.181474344852643,\n",
       " 0.24494051462936942)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"pretrained only t2m\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cee809d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(\"pretrained mix\")\n",
    "# best_fid_k = []\n",
    "# best_fid_g = []\n",
    "# best_div_k = []\n",
    "# best_div_g = []\n",
    "# best_beat_align = []\n",
    "\n",
    "# for i in range(20):\n",
    "\n",
    "#     a,b,c,d,e = evaluate_music_motion_vqvae(aist_loader,vqvae_model)\n",
    "#     best_fid_k.append(a)\n",
    "#     best_fid_g.append(b)\n",
    "#     best_div_k.append(c)\n",
    "#     best_div_g.append(d)\n",
    "#     best_beat_align.append(e)\n",
    "\n",
    "    \n",
    "# print(\"best_fid_k\" , np.mean(best_fid_k))\n",
    "# print(\"best_fid_g\" , np.mean(best_fid_g))\n",
    "# print(\"best_div_k\" , np.mean(best_div_k))\n",
    "# print(\"best_div_g\" , np.mean(best_div_g))\n",
    "# print(\"best_beat_align\" , np.mean(best_beat_align))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905d603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:39<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  2.635362356342995 Diversity_k: 10.163608189500295\n",
      "FID_g:  7.295345718653849 Diversity_g: 7.234946262225127\n",
      "FID_k_real:  -7.757004908626186e-06 Diversity_k_real: 10.205963216454554\n",
      "FID_g_real:  -1.903529778246593e-09 Diversity_g_real: 7.344472836225461\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.635362356342995,\n",
       " 7.295345718653849,\n",
       " 10.163608189500295,\n",
       " 7.234946262225127,\n",
       " 0.244130060202235)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"mix\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5165ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635881b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "727139c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained only t2m, finetuned only aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:01<00:37,  1.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-88106f13813e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pretrained only t2m, finetuned only aist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_music_motion_vqvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maist_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvqvae_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/coc/scratch/sanisetty3/music_motion/motion_vqvae/utils/eval_music.py\u001b[0m in \u001b[0;36mevaluate_music_motion_vqvae\u001b[0;34m(val_loader, net, audio_feature_dir, best_fid_k, best_fid_g, best_div_k, best_div_g, best_beat_align)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mkeypoints3d_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecover_from_ric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_motion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmot_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mreal_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mreal_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"manual\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"manual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/coc/scratch/sanisetty3/music_motion/motion_vqvae/utils/aist_metrics/calculate_fid_scores.py\u001b[0m in \u001b[0;36mextract_feature\u001b[0;34m(keypoints3d, mode)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"kinetic\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_kinetic_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"manual\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_manual_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/aist_plusplus/features/kinetic.py\u001b[0m in \u001b[0;36mextract_kinetic_features\u001b[0;34m(positions)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_kinetic_energy_horizontal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_kinetic_energy_vertical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_energy_expenditure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             ]\n\u001b[1;32m     47\u001b[0m         )\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/aist_plusplus/features/kinetic.py\u001b[0m in \u001b[0;36maverage_energy_expenditure\u001b[0;34m(self, joint)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             val += feat_utils.calc_average_acceleration(\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliding_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             )\n\u001b[1;32m    110\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/aist_plusplus/features/utils.py\u001b[0m in \u001b[0;36mcalc_average_acceleration\u001b[0;34m(positions, i, joint_idx, sliding_window, frame_time)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjoint_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mframe_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         )\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0maverage_acceleration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mframe_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mcurrent_window\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_acceleration\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcurrent_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"pretrained only t2m, finetuned only aist\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26b752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b755169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f091bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [29:56<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.010750366559051372 Diversity_k: 9.172959109891172\n",
      "FID_g:  1.2350136226828567 Diversity_g: 7.381343867734843\n",
      "\n",
      "Beat score on real data: 0.249\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.010750366559051372,\n",
       " 1.2350136226828567,\n",
       " 9.172959109891172,\n",
       " 7.381343867734843,\n",
       " 0.24940255611332512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Mixture\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6807ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cbf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "929e37dd",
   "metadata": {},
   "source": [
    "## Generating token dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2851ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.05, 135.15, 204.0, 127.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.11*255, 0.53*255, 0.8*255, 0.5*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ebded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567edaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cda3fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:01<00:00, 1244.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "128f1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [01:47<00:00, 17.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(aist_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "#         ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "        inds = []\n",
    "        for i in range(0 , n, 200):\n",
    "            ii = vqvae_model.encode(batch[\"motion\"][:,i:i+200].cuda())\n",
    "            inds.append(ii[0])\n",
    "#             print(ii.shape)\n",
    "        \n",
    "        ind = torch.concatenate(inds)[None,...]\n",
    "        \n",
    "#     print(ind.shape)\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/AIST/joint_indices\" , name+\".npy\"),ind.cpu().numpy()[0])\n",
    "        \n",
    "#         quant , out_motion = vqvae_model.decode(ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a8506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88345291",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_list = glob(\"/srv/scratch/sanisetty3/music_motion/AIST/joint_indices/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9bd1f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(mot_list[0]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf69f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "for i in mot_list:\n",
    "    lens.append(np.load(i).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea60d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa63c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55b6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23384/23384 [08:53<00:00, 43.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 23384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hlm_ds = VQFullMotionDataset(\"t2m\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/\" , window_size = -1)\n",
    "hlm_loader = DATALoader(hlm_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fc337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914ddffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23384 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(hlm_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "429fe4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 M003397\n"
     ]
    }
   ],
   "source": [
    "n = int(batch[\"motion_lengths\"])\n",
    "name = str(batch[\"names\"][0])\n",
    "print(n,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6512a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(batch[\"motion\"].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d80c572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 199])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06dcf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23384 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices/007648.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7e92969d732f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/srv/share2/sanisetty3/miniconda3/envs/ai-choreo/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices/007648.npy'"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(hlm_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "        #ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "#         out_motion = torch.zeros((batch[\"motion\"].shape[0] ,gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "        inds = []\n",
    "        for i in range(0 , n, 200):\n",
    "            inds.append(vqvae_model.encode(batch[\"motion\"].cuda()))\n",
    "        \n",
    "        ind = torch.stack(inds)\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices\" , name+\".npy\"), ind.cpu().numpy()[0])\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14428964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507abd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(batch[\"motion\"][0:1].detach().cpu(),mean = hlm_ds.mean , std = hlm_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc99328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb20b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a0b19e9",
   "metadata": {},
   "source": [
    "## T2M Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils_model as utils_model\n",
    "from core.datasets import dataset_TM_eval\n",
    "import utils.eval_trans as eval_trans\n",
    "from core.models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "from utils.eval_trans import evaluation_vqvae_loss,evaluation_vqvae\n",
    "from utils.eval_trans import calculate_R_precision,calculate_activation_statistics,calculate_diversity,calculate_frechet_distance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdecf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [02:23<00:00, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4648 4648\n",
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_vectorizer = WordVectorizer('/srv/scratch/sanisetty3/music_motion/T2M-GPT/glove', 'our_vab')\n",
    "eval_wrapper = EvaluatorModelWrapper(cfg.eval_model)\n",
    "tm_eval = dataset_TM_eval.DATALoader(\"t2m\", True, 20, w_vectorizer, unit_length=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5f5af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646f4266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([275000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "load_path = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_aist/vqvae_motion.pt\"\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"{load_path}\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253031f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75682d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:43<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0668, Diversity Real. 9.5584, Diversity. 9.9187, R_precision_real. [0.60193966 0.78189655 0.86810345], R_precision. [0.59439655 0.77801724 0.85991379], matching_score_real. 2.9862875124503825, matching_score_pred. 3.028119134902954\n"
     ]
    }
   ],
   "source": [
    "### Pretrained on t2m only\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1454baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained on t2m only and finetuned on aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:43<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 3.2204, Diversity Real. 9.3818, Diversity. 7.4288, R_precision_real. [0.59698276 0.78728448 0.86551724], R_precision. [0.43512931 0.64073276 0.75625   ], matching_score_real. 2.9870332890543443, matching_score_pred. 4.043809700012207\n"
     ]
    }
   ],
   "source": [
    "print(\"pretrained on t2m only and finetuned on aist\")\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701a9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad4ce29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:42<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0637, Diversity Real. 9.4620, Diversity. 9.4266, R_precision_real. [0.61616379 0.79482759 0.86982759], R_precision. [0.60172414 0.78405172 0.86077586], matching_score_real. 2.9635313979510602, matching_score_pred. 3.0240239735307366\n"
     ]
    }
   ],
   "source": [
    "## Pretrained on a mix of aist and t2m\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fe5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
