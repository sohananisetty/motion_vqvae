{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcaaaca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d978f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1c9ffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glob\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "import visualize.plot_3d_global as plot_3d\n",
    "from glob import glob\n",
    "def to_xyz(motion, mean ,std , j = 22):\n",
    "    motion_xyz = recover_from_ric(motion.cpu().float()*std+mean, j)\n",
    "    motion_xyz = motion_xyz.reshape(motion.shape[0],-1, j, 3)\n",
    "    return motion_xyz\n",
    "\n",
    "            \n",
    "def sample_render(motion_xyz , name , save_path):\n",
    "    print(f\"render start\")\n",
    "    \n",
    "    gt_pose_vis = plot_3d.draw_to_batch(motion_xyz.numpy(),None, [os.path.join(save_path,name + \".gif\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_model = MotionRegressorModel(args = cfg.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_model = VQMotionModel(cfg.vqvae).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75437290",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae_model = VQMotionModel(cfg.vqvae).eval()\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = MotionCollator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50424dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 60 - 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1169.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = VQVarLenMotionDataset(\"t2m\", split = \"render\" , max_length_seconds = 10, data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D\")\n",
    "train_loader = DATALoader(train_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc774b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 2111.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQVarLenMotionDataset(\"aist\", split = \"render\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , num_stages = 6 ,min_length_seconds=20, max_length_seconds=30)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f32fea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 600\n"
     ]
    }
   ],
   "source": [
    "aist_loader.dataset.set_stage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da01534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 191, 263])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for aist_batch in aist_loader:\n",
    "    break\n",
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gBR_sFM_cAll_d06_mBR3_ch17 589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5565fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gBR_sFM_cAll_d06_mBR3_ch17'], dtype='<U26')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aist_batch[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3683b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b565e8",
   "metadata": {},
   "source": [
    "## Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fb8e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 191])\n"
     ]
    }
   ],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"].cuda())\n",
    "print(ind.shape)\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f010f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.empty(aist_batch[\"motion\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bf733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c188c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"][:,:400].cuda())\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41c3dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant , out_motion = vqvae_model.decode(ind[:,400:].to(torch.long).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5411013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,400:] = out_motion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d67a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_og_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "241a5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion_ind_400\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ebcdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(0,1024,(1,60))\n",
    "quant , out_motion = vqvae_model.decode(indices.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90379db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f95c09",
   "metadata": {},
   "source": [
    "## Music Eval stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45ad8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "from aist_features import calculate_fid_scores\n",
    "from aist_features.calculate_fid_scores import calculate_avg_distance, extract_feature,calculate_frechet_feature_distance,calculate_frechet_distance\n",
    "from aist_features.features import kinetic,manual\n",
    "from aist_features.calculate_beat_scores import motion_peak_onehot,alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "088f2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e14fb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2240ff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:01<00:00, 1282.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = 400)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f24604a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1910 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for aist_batch in tqdm(aist_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb037dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [46:44<00:00,  1.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.028328037164357056 Diversity_k: 9.260323240545652\n",
      "FID_g:  1.2220429949585352 Diversity_g: 7.300148475695237\n",
      "\n",
      "Beat score on real data: 0.250\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.246\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.028328037164357056, 1.2220429949585352, 100, 100, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e37dd",
   "metadata": {},
   "source": [
    "## Generating token dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cda3fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1513.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"render\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "128f1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 14.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(aist_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/AIST/joint_indices_max_400\" , name+\".npy\"),ind.cpu().numpy()[0])\n",
    "        \n",
    "#         quant , out_motion = vqvae_model.decode(ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb20b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2321fdf",
   "metadata": {},
   "source": [
    "## Motion generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a3d980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import MotionCollatorConditional,VQVarLenMotionDatasetConditional, TransMotionDatasetConditional\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c874cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "trans_model = MotionRegressorModel(args = cfg.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "836ba999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkg3 = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "trans_model.load_state_dict(pkg3[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7d3454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = VQMotionModel(cfg.vqvae).eval()\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0700c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:02<00:00, 932.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = TransMotionDatasetConditional(\"aist\", split = \"train\",data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , datafolder=\"joint_indices_max_400\", window_size = 400,force_len=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7230e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn2 = MotionCollatorConditional(dataset_name = \"aist\" , bos = 1024, pad = 1025, eos = 1026)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d206a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DATALoader(train_ds , batch_size = 1,collate_fn=collate_fn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aaf3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c09a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg_batch in dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef6b7e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion torch.Size([1, 175])\n",
      "motion_lengths torch.Size([1])\n",
      "motion_mask torch.Size([1, 175])\n",
      "names (1,)\n",
      "condition torch.Size([1, 174, 128])\n",
      "condition_mask torch.Size([1, 174])\n"
     ]
    }
   ],
   "source": [
    "for k,v in reg_batch.items():\n",
    "    print(k , v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c13f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target = reg_batch[\"motion\"][:, :-1], reg_batch[\"motion\"][:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "914c8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant , out_motion = vqvae_model.decode(target[target<1024][None,...].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7cbc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = train_ds.mean , std = train_ds.std), \"rnd_og_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4968b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:10<00:04,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "gen_motion_indices = trans_model.generate(start_tokens = inp[:,:1], seq_len=100 , context = reg_batch[\"condition\"], context_mask = reg_batch[\"condition_mask\"], eos_token=1026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81e62e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 307,  912,  912,  564,  564,  200,  904,   83,   92,   92,  246,  182,\n",
       "          460,  282,  282, 1022,  486,  470,  540,    2,  578,  564,  612,  757,\n",
       "           92,   23,  184,  229,  113,  824,  120,  675,  675,  813,  460,  905,\n",
       "          212, 1022, 1022,  282,  997,  152,  373,  962,  905,  400,  617,  841,\n",
       "          617,  510,  634,  102,  617,  483,  813,   37,  617,  331,   76,  617,\n",
       "          180,  672,  367,  813,  612,  757,   94,  175,  840,  232,  787,  460]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_motion_indices[gen_motion_indices<1024][None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec9fe91f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vqvae_model = vqvae_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c7fa1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "quant , out_motion = vqvae_model.decode(gen_motion_indices[gen_motion_indices<1024][None,...].cuda())\n",
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = train_ds.mean , std = train_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21c74130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_trans\n",
    "evaluate_music_motion_trans(dl, vqvae_model, trans_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c94e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4c4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a0b19e9",
   "metadata": {},
   "source": [
    "## T2M Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils_model as utils_model\n",
    "from core.datasets import dataset_TM_eval\n",
    "import utils.eval_trans as eval_trans\n",
    "from core.models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "from utils.eval_trans import evaluation_vqvae_loss,evaluation_vqvae\n",
    "from utils.eval_trans import calculate_R_precision,calculate_activation_statistics,calculate_diversity,calculate_frechet_distance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdecf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [00:04<00:00, 912.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4648 4648\n",
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_vectorizer = WordVectorizer('/srv/scratch/sanisetty3/music_motion/T2M-GPT/glove', 'our_vab')\n",
    "eval_wrapper = EvaluatorModelWrapper(cfg.eval_model)\n",
    "tm_eval = dataset_TM_eval.DATALoader(\"t2m\", True, 20, w_vectorizer, unit_length=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad4ce29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:42<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0637, Diversity Real. 9.4620, Diversity. 9.4266, R_precision_real. [0.61616379 0.79482759 0.86982759], R_precision. [0.60172414 0.78405172 0.86077586], matching_score_real. 2.9635313979510602, matching_score_pred. 3.0240239735307366\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fe5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b36dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1185044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
