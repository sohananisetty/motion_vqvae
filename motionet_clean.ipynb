{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcaaaca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d978f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120cfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "import visualize.plot_3d_global as plot_3d\n",
    "from glob import glob\n",
    "def to_xyz(motion, mean ,std , j = 22):\n",
    "    motion_xyz = recover_from_ric(motion.cpu().float()*std+mean, j)\n",
    "    motion_xyz = motion_xyz.reshape(motion.shape[0],-1, j, 3)\n",
    "    return motion_xyz\n",
    "\n",
    "            \n",
    "def sample_render(motion_xyz , name , save_path):\n",
    "    print(f\"render start\")\n",
    "    \n",
    "    gt_pose_vis = plot_3d.draw_to_batch(motion_xyz.numpy(),None, [os.path.join(save_path,name + \".gif\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fb7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7431cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_model = MotionRegressorModel(args = cfg.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b9f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75437290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5556bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = MotionCollator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50424dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 60 - 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 37.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = VQVarLenMotionDataset(\"t2m\", split = \"render\" , max_length_seconds = 10, data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D\")\n",
    "train_loader = DATALoader(train_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc774b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 39.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQVarLenMotionDataset(\"aist\", split = \"render\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , num_stages = 6 ,min_length_seconds=20, max_length_seconds=30)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32fea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 600\n"
     ]
    }
   ],
   "source": [
    "aist_loader.dataset.set_stage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da01534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 159, 263])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for aist_batch in aist_loader:\n",
    "    break\n",
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gBR_sFM_cAll_d06_mBR3_ch17 589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5565fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gBR_sFM_cAll_d06_mBR3_ch17'], dtype='<U26')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aist_batch[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3683b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17a994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99107113",
   "metadata": {},
   "source": [
    "## Trans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e491b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca3b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([195000.])\n"
     ]
    }
   ],
   "source": [
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58013d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e6dc97a",
   "metadata": {},
   "source": [
    "## Render SMPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c0db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from render_final import render\n",
    "from core.datasets.vqa_motion_dataset import TransMotionDatasetConditionalFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358d8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 58.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = TransMotionDatasetConditionalFull(\"aist\", split = \"test\",data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , datafolder=\"joint_indices_max_400\", window_size = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec73aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions_list = glob(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/generator/var_len/trans_768_768_albi_aist/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba139e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1012fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "name =os.path.basename( motions_list[2]).split(\".\")[0]\n",
    "motion = np.load(motions_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b05675",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_xyz = to_xyz(torch.Tensor(motion) , mean=train_ds.mean , std = train_ds.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d7c9bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 401, 22, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f92ce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mHO4'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f4e1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/pos/{name}.npy\" , motion_xyz.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47f6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c7babc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "render(motion_xyz[0].numpy(), outdir=\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/generator/var_len/trans_768_768_albi_aist/SMPL\", name=name, pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef66d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd0b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec46c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b565e8",
   "metadata": {},
   "source": [
    "## Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fb8e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 191])\n"
     ]
    }
   ],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"].cuda())\n",
    "print(ind.shape)\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f010f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.empty(aist_batch[\"motion\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bf733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c188c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"][:,:400].cuda())\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41c3dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant , out_motion = vqvae_model.decode(ind[:,400:].to(torch.long).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5411013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,400:] = out_motion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d67a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_og_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "241a5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion_ind_400\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ebcdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(0,1024,(1,60))\n",
    "quant , out_motion = vqvae_model.decode(indices.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90379db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f95c09",
   "metadata": {},
   "source": [
    "## Music Eval stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df396922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ad8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "from utils.aist_metrics import calculate_fid_scores\n",
    "from utils.aist_metrics.calculate_fid_scores import calculate_avg_distance, extract_feature,calculate_frechet_feature_distance,calculate_frechet_distance\n",
    "from utils.aist_metrics.features import kinetic,manual\n",
    "from utils.aist_metrics.calculate_beat_scores import motion_peak_onehot,alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "088f2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import MotionCollatorConditional, TransMotionDatasetConditional,VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e14fb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae, evaluate_music_motion_generative,evaluate_music_motion_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2240ff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 75.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = 400)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24604a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for aist_batch in tqdm(aist_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b85a62",
   "metadata": {},
   "source": [
    "### Const len trained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c1c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([85000.])\n"
     ]
    }
   ],
   "source": [
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/const_len/trans_768_768_aist/vqvae_motion.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea564d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0365a3a3",
   "metadata": {},
   "source": [
    "## Evaluate Music Motion transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "518c307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_35/var_len_768_768_aist_35.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da714b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n",
    "# pkg_trans = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "# print(pkg_trans[\"steps\"])\n",
    "# trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "# trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcda749a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransMotionDatasetConditional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5c85c4993f1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maist_train_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransMotionDatasetConditional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aist\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/srv/scratch/sanisetty3/music_motion/AIST\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdatafolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"joint_indices_max_400\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmusicfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"audio_features\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcollate_fn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMotionCollatorConditional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"aist\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mclip_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1026\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maist_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATALoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maist_train_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TransMotionDatasetConditional' is not defined"
     ]
    }
   ],
   "source": [
    "aist_train_ds = TransMotionDatasetConditional(\"aist\", split = \"test\",data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , datafolder=\"joint_indices_max_400\",  musicfolder = \"audio_features\",window_size = 400)\n",
    "collate_fn2 = MotionCollatorConditional(dataset_name = \"aist\" , clip_model=None, bos = 1024, pad = 1025, eos = 1026)\n",
    "\n",
    "aist_loader = DATALoader(aist_train_ds,1,collate_fn=collate_fn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40f82831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:59<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  18.804652039617977 Diversity_k: 10.770400709677965\n",
      "FID_g:  16.69040273581212 Diversity_g: 7.901337711627667\n",
      "Beat score on real data: 0.236\n",
      "\n",
      "Beat score on generated data: 0.237\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.804652039617977,\n",
       " 16.69040273581212,\n",
       " 10.770400709677965,\n",
       " 7.901337711627667,\n",
       " 0.23594613690266134)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " evaluate_music_motion_trans(aist_loader,vqvae_model , trans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81752e",
   "metadata": {},
   "source": [
    "## Evaluate Music Motion Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e41c4914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:12<00:00, 32.23it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.10it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 42.74it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.71it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.94it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.43it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 42.97it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.01it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.79it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.22it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 44.55it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 42.82it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.42it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.91it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.63it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.76it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 42.91it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.82it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.38it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.99it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.51it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.37it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 44.62it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.08it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.96it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.54it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.33it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.09it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.34it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.94it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.31it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 42.96it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.29it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.37it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 45.65it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.76it/s]\n",
      "100%|██████████| 400/400 [00:09<00:00, 43.19it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.58it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 46.54it/s]\n",
      "100%|██████████| 400/400 [00:08<00:00, 44.84it/s]\n",
      "100%|██████████| 40/40 [06:58<00:00, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  3.8717503038434415 Diversity_k: 10.580599220288105\n",
      "FID_g:  14.323117971786502 Diversity_g: 7.208645957555526\n",
      "\n",
      "Beat score on real data: 0.244\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.8717503038434415,\n",
       " 14.323117971786502,\n",
       " 10.580599220288105,\n",
       " 7.208645957555526,\n",
       " 0.24413006020223502)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_generative(aist_loader , vqvae_model= vqvae_model ,net = trans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad058c8",
   "metadata": {},
   "source": [
    "## Sinusoidal pos emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2797d1",
   "metadata": {},
   "source": [
    "FID_k:  3.8717503038434415 Diversity_k: 10.580599220288105\n",
    "FID_g:  14.323117971786502 Diversity_g: 7.208645957555526\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8adb76",
   "metadata": {},
   "source": [
    "### Albi\n",
    "\n",
    "FID_k:  5.974822501678858 Diversity_k: 9.894211104435799\n",
    "FID_g:  10.945797702730552 Diversity_g: 7.33098736114991\n",
    "\n",
    "Beat score on real data: 0.244\n",
    "\n",
    "\n",
    "Beat score on generated data: 0.207"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32409bf",
   "metadata": {},
   "source": [
    "### Music VQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f949902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from utils.eval_music import evaluate_music_motion_vqvae\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "load_path = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82eab47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"{load_path}\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b62b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7a4d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1795.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = 200)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9d5d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained only t2m, finetuned only aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  2.0920801447029476 Diversity_k: 10.220271441416863\n",
      "FID_g:  7.253544086152061 Diversity_g: 7.204830408401978\n",
      "\n",
      "Beat score on real data: 0.245\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.237\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.0920801447029476,\n",
       " 7.253544086152061,\n",
       " 10.220271441416863,\n",
       " 7.204830408401978,\n",
       " 0.24494051462936942)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"pretrained only t2m, finetuned only aist\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a348b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  2.428534823928004 Diversity_k: 10.020026898880799\n",
      "FID_g:  6.612723451771529 Diversity_g: 7.239648975470128\n",
      "\n",
      "Beat score on real data: 0.245\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.428534823928004,\n",
       " 6.612723451771529,\n",
       " 10.020026898880799,\n",
       " 7.239648975470128,\n",
       " 0.24494051462936942)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"pretrained mix\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd8a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ec17a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained only t2m, finetuned only aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [30:31<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.009076383795559195 Diversity_k: 9.195408521088853\n",
      "FID_g:  2.6327930699114575 Diversity_g: 7.313916773284796\n",
      "\n",
      "Beat score on real data: 0.249\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.251\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009076383795559195,\n",
       " 2.6327930699114575,\n",
       " 9.195408521088853,\n",
       " 7.313916773284796,\n",
       " 0.24940255611332515)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"pretrained only t2m, finetuned only aist\")\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2270e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [29:56<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.010750366559051372 Diversity_k: 9.172959109891172\n",
      "FID_g:  1.2350136226828567 Diversity_g: 7.381343867734843\n",
      "\n",
      "Beat score on real data: 0.249\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.010750366559051372,\n",
       " 1.2350136226828567,\n",
       " 9.172959109891172,\n",
       " 7.381343867734843,\n",
       " 0.24940255611332512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Mixture\n",
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117c8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc85f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb037dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [46:44<00:00,  1.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.028328037164357056 Diversity_k: 9.260323240545652\n",
      "FID_g:  1.2220429949585352 Diversity_g: 7.300148475695237\n",
      "\n",
      "Beat score on real data: 0.250\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.246\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.028328037164357056, 1.2220429949585352, 100, 100, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e37dd",
   "metadata": {},
   "source": [
    "## Generating token dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cda3fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1513.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"render\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "128f1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 14.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(aist_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/AIST/joint_indices_max_400\" , name+\".npy\"),ind.cpu().numpy()[0])\n",
    "        \n",
    "#         quant , out_motion = vqvae_model.decode(ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa63c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c55b6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [00:15<00:00, 290.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hlm_ds = VQFullMotionDataset(\"t2m\", split = \"test\" , data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/\" , window_size = -1)\n",
    "hlm_loader = DATALoader(hlm_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "914ddffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1460 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(hlm_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "429fe4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 007326\n"
     ]
    }
   ],
   "source": [
    "n = int(batch[\"motion_lengths\"])\n",
    "name = str(batch[\"names\"][0])\n",
    "print(n,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d06dcf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [03:07<00:00, 23.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(hlm_loader):\n",
    "    \n",
    "    n = int(batch[\"motion_lengths\"])\n",
    "    name = str(batch[\"names\"][0])\n",
    "    if n< 400:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"].cuda())\n",
    "    else:\n",
    "        ind = vqvae_model.encode(batch[\"motion\"][:,:400].cuda())\n",
    "    \n",
    "    np.save(os.path.join(\"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/joint_indices_max_400\" , name+\".npy\"), ind.cpu().numpy()[0])\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14428964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507abd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(batch[\"motion\"][0:1].detach().cpu(),mean = hlm_ds.mean , std = hlm_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc99328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb20b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a0b19e9",
   "metadata": {},
   "source": [
    "## T2M Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils_model as utils_model\n",
    "from core.datasets import dataset_TM_eval\n",
    "import utils.eval_trans as eval_trans\n",
    "from core.models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "from utils.eval_trans import evaluation_vqvae_loss,evaluation_vqvae\n",
    "from utils.eval_trans import calculate_R_precision,calculate_activation_statistics,calculate_diversity,calculate_frechet_distance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdecf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [02:23<00:00, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4648 4648\n",
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_vectorizer = WordVectorizer('/srv/scratch/sanisetty3/music_motion/T2M-GPT/glove', 'our_vab')\n",
    "eval_wrapper = EvaluatorModelWrapper(cfg.eval_model)\n",
    "tm_eval = dataset_TM_eval.DATALoader(\"t2m\", True, 20, w_vectorizer, unit_length=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5f5af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef3618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([275000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "load_path = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_aist/vqvae_motion.pt\"\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"{load_path}\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d586312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcabf79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:43<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0668, Diversity Real. 9.5584, Diversity. 9.9187, R_precision_real. [0.60193966 0.78189655 0.86810345], R_precision. [0.59439655 0.77801724 0.85991379], matching_score_real. 2.9862875124503825, matching_score_pred. 3.028119134902954\n"
     ]
    }
   ],
   "source": [
    "### Pretrained on t2m only\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c8b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained on t2m only and finetuned on aist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:43<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 3.2204, Diversity Real. 9.3818, Diversity. 7.4288, R_precision_real. [0.59698276 0.78728448 0.86551724], R_precision. [0.43512931 0.64073276 0.75625   ], matching_score_real. 2.9870332890543443, matching_score_pred. 4.043809700012207\n"
     ]
    }
   ],
   "source": [
    "print(\"pretrained on t2m only and finetuned on aist\")\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c5add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b2e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad4ce29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:42<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0637, Diversity Real. 9.4620, Diversity. 9.4266, R_precision_real. [0.61616379 0.79482759 0.86982759], R_precision. [0.60172414 0.78405172 0.86077586], matching_score_real. 2.9635313979510602, matching_score_pred. 3.0240239735307366\n"
     ]
    }
   ],
   "source": [
    "## Pretrained on a mix of aist and t2m\n",
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fe5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
