{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb0934dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e4b7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a81048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a6a56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "import visualize.plot_3d_global as plot_3d\n",
    "from glob import glob\n",
    "def to_xyz(motion, mean ,std , j = 22):\n",
    "    motion_xyz = recover_from_ric(motion.cpu().float()*std+mean, j)\n",
    "    motion_xyz = motion_xyz.reshape(motion.shape[0],-1, j, 3)\n",
    "    return motion_xyz\n",
    "\n",
    "            \n",
    "def sample_render(motion_xyz , name , save_path):\n",
    "    print(f\"render start\")\n",
    "    \n",
    "    gt_pose_vis = plot_3d.draw_to_batch(motion_xyz.numpy(),None, [os.path.join(save_path,name + \".gif\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b495e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01351b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c9dc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = MotionRegressorModel(args = cfg.motion_trans , ignore_index=1025 ,pad_value=1025 ).eval()\n",
    "vqvae_model = VQMotionModel(cfg.vqvae).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ab10539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "# step = 320000\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28f5db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = MotionCollator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe088236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 60 - 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1169.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = VQVarLenMotionDataset(\"t2m\", split = \"render\" , max_length_seconds = 10, data_root = \"/srv/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D\")\n",
    "train_loader = DATALoader(train_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fb08be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:00<00:00, 2036.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQVarLenMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , num_stages = 6 ,min_length_seconds=20, max_length_seconds=30)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1557e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing range to: 400 - 600\n"
     ]
    }
   ],
   "source": [
    "aist_loader.dataset.set_stage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c630190c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 463, 263])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for aist_batch in aist_loader:\n",
    "    break\n",
    "aist_batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d6a3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e251561",
   "metadata": {},
   "source": [
    "## Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a82f1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"].cuda())\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "208988ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.empty(aist_batch[\"motion\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cde0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbb11430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = vqvae_model.encode(aist_batch[\"motion\"][:,:400].cuda())\n",
    "quant , out_motion = vqvae_model.decode(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2924acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant , out_motion = vqvae_model.decode(ind[:,400:].to(torch.long).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a63e5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,400:] = out_motion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e640cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(aist_batch[\"motion\"][0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_og_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acb21424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion_ind_400\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8bfb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randint(0,1024,(1,60))\n",
    "quant , out_motion = vqvae_model.decode(indices.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99560e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "render start\n"
     ]
    }
   ],
   "source": [
    "sample_render(to_xyz(out_motion[0:1].detach().cpu(),mean = aist_ds.mean , std = aist_ds.std), \"rnd_motion\" , \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/evals/decode_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fab92",
   "metadata": {},
   "source": [
    "## Music Eval stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61c072c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.motion_process import recover_from_ric\n",
    "from aist_features import calculate_fid_scores\n",
    "from aist_features.calculate_fid_scores import calculate_avg_distance, extract_feature,calculate_frechet_feature_distance,calculate_frechet_distance\n",
    "from aist_features.features import kinetic,manual\n",
    "from aist_features.calculate_beat_scores import motion_peak_onehot,alignment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c74045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5c2deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_vqvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8eecbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4fcf04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:22<00:00, 84.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = 400)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "40a1204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1910 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for aist_batch in tqdm(aist_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be5844bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [46:44<00:00,  1.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID_k:  0.028328037164357056 Diversity_k: 9.260323240545652\n",
      "FID_g:  1.2220429949585352 Diversity_g: 7.300148475695237\n",
      "\n",
      "Beat score on real data: 0.250\n",
      "\n",
      "\n",
      "Beat score on generated data: 0.246\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.028328037164357056, 1.2220429949585352, 100, 100, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_music_motion_vqvae(aist_loader,vqvae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34bca9",
   "metadata": {},
   "source": [
    "## Motion generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 320000\n",
    "pkg2 = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_aist/vqvae_motion.pt\", map_location = 'cpu')\n",
    "print(pkg2[\"steps\"])\n",
    "vqvae_model_prev.load_state_dict(pkg2[\"model\"])\n",
    "vqvae_model_prev =vqvae_model_prev.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d89f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg3 = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/const_len/\", map_location = 'cpu')\n",
    "reg_model.load_state_dict(pkg3[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f4fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba9d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288dffb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d41c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5453c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152a17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a79a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7258f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c9d507",
   "metadata": {},
   "source": [
    "## T2M Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71db7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils_model as utils_model\n",
    "from core.datasets import dataset_TM_eval\n",
    "import utils.eval_trans as eval_trans\n",
    "from core.models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "from utils.eval_trans import evaluation_vqvae_loss,evaluation_vqvae\n",
    "from utils.eval_trans import calculate_R_precision,calculate_activation_statistics,calculate_diversity,calculate_frechet_distance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff56c991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4384/4384 [00:04<00:00, 912.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4648 4648\n",
      "Pointer Pointing at 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_vectorizer = WordVectorizer('/srv/scratch/sanisetty3/music_motion/T2M-GPT/glove', 'our_vab')\n",
    "eval_wrapper = EvaluatorModelWrapper(cfg.eval_model)\n",
    "tm_eval = dataset_TM_eval.DATALoader(\"t2m\", True, 20, w_vectorizer, unit_length=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef42d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:42<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> \t Eva. Iter 0 :, FID. 0.0637, Diversity Real. 9.4620, Diversity. 9.4266, R_precision_real. [0.61616379 0.79482759 0.86982759], R_precision. [0.60172414 0.78405172 0.86077586], matching_score_real. 2.9635313979510602, matching_score_pred. 3.0240239735307366\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluation_vqvae_loss(val_loader = tm_eval, net= vqvae_model,nb_iter= 0, eval_wrapper = eval_wrapper,save = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48068c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16550e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638ddad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef1a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
