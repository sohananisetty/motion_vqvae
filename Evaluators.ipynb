{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa4d2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedec771",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5dbff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c16c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vqa_motion_dataset import MotionCollatorConditional, TransMotionDatasetConditional,VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator,VQFullMotionDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "1fbb6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in aist_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "99ae543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 147, 263])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"motion\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d50fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.eval_modules import AISTEncoderBiGRUCo\n",
    "\n",
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_e = get_cfg_defaults()\n",
    "cfg_e.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/extractors/small/aist_extractor.yaml\")\n",
    "\n",
    "\n",
    "motion_extractor = AISTEncoderBiGRUCo(cfg_e.extractor.motion_input_size,cfg_e.extractor.hidden_size,cfg_e.extractor.output_size)\n",
    "music_extractor =  AISTEncoderBiGRUCo(cfg_e.extractor.music_input_size,cfg_e.extractor.hidden_size,cfg_e.extractor.output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3f1c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([120000.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "chk = torch.load(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/extractors/small/checkpoints/extractors.120000.pt\")\n",
    "print(chk[\"steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2de40b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AISTEncoderBiGRUCo(\n",
       "  (input_emb): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (gru): GRU(256, 256, batch_first=True, bidirectional=True)\n",
       "  (output_net): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_extractor.load_state_dict(chk[\"motion_extractor\"])\n",
    "music_extractor.load_state_dict(chk[\"music_extractor\"])\n",
    "motion_extractor.eval()\n",
    "music_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264fdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79f05b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:03<00:00, 534.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2dae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c27c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_musics_list = glob(\"/srv/scratch/sanisetty3/music_motion/AIST/music/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6328b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/scratch/sanisetty3/music_motion/AIST/music/mWA0.npy'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gt_musics_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700d3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_encodings = []\n",
    "music_encodings_name = []\n",
    "for i in (gt_musics_list):\n",
    "    musc = torch.Tensor(np.load(i))\n",
    "    ec = music_extractor(musc[None,...],torch.Tensor([musc.shape[0]]))\n",
    "    music_encodings.append(ec)\n",
    "    music_encodings_name.append(os.path.basename(i).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2cf98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_encodings_np = torch.cat(music_encodings, dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8902f2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_encodings_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.evaluator_dataset import EvaluatorMotionCollator, EvaluatorVarLenMotionDataset,EvaluatorMotionDataset\n",
    "# aist_ds = EvaluatorVarLenMotionDataset(split = \"test\" ,data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" ,num_stages = 6 ,min_length_seconds=10, max_length_seconds=40)\n",
    "aist_ds = EvaluatorMotionDataset(split = \"train\" ,data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" ,window_size = -1 )\n",
    "\n",
    "collate_fn = EvaluatorMotionCollator()\n",
    "\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ade610b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:11<00:00, 168.27it/s]\n"
     ]
    }
   ],
   "source": [
    "em_ = []\n",
    "ec_ = []\n",
    "names = []\n",
    "\n",
    "for batch in tqdm(aist_loader):\n",
    "#     if  int(batch[\"motion_lengths\"][0]) < 600:\n",
    "#         continue\n",
    "#     if len(em_) > 40:\n",
    "#         break\n",
    "\n",
    "    music_name = batch[\"names\"][0].split(\"_\")[-2]\n",
    "    \n",
    "\n",
    "    if music_name not in names:\n",
    "        names.append(music_name)\n",
    "\n",
    "        em = motion_extractor(batch[\"motion\"], batch[\"motion_lengths\"])\n",
    "        ec = music_extractor(batch[\"condition\"],batch[\"motion_lengths\"])\n",
    "        em_.append(em)\n",
    "        ec_.append(ec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a583586b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3923081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_np = torch.cat(em_, dim=0).detach().cpu().numpy()\n",
    "ec_np = torch.cat(ec_, dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d897ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "880230af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1562], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(torch.Tensor(em_[0]),torch.Tensor(ec_[2]) , dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69b8af97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9913,  0.5768,  0.1613, -0.0533,  0.4460,  0.2672,  0.4311,  0.9829,\n",
       "         0.9856,  0.9898, -0.0078,  0.9932, -0.0476,  0.2012,  0.9919,  0.5833,\n",
       "         0.9859,  0.9884,  0.3937,  0.9925,  0.1603, -0.0210,  0.2217,  0.9904,\n",
       "         0.6562,  0.6452,  0.3598,  0.9829,  0.3401,  0.1761,  0.1444,  0.9941,\n",
       "         0.6559,  0.4310, -0.0039,  0.4904, -0.1530,  0.9917,  0.9874,  0.9887,\n",
       "        -0.0311,  0.2942, -0.0044,  0.1604, -0.0897,  0.9888,  0.9911,  0.4894,\n",
       "         0.2795,  0.7688,  0.9928,  0.1289])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(torch.Tensor(em_np),torch.Tensor(ec_np) , dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0003e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44604453  0.08645589 -0.20496403  0.0420238 ]\n",
      " [ 0.08076429  0.26715535 -0.07636566 -0.15384707]\n",
      " [-0.05276822 -0.0871304   0.431055    0.06496669]\n",
      " [ 0.02543228 -0.03414407 -0.07645725  0.9829299 ]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(em_np , ec_np)[4:8,4:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668ac09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1e9a137d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mJB0 [25]\n",
      "music:  mWA0 motion : mJB0 -0.08787343\n",
      "music:  mHO0 motion : mJB0 0.032452673\n",
      "music:  mJB0 motion : mJB0 0.36589286\n",
      "music:  mMH0 motion : mJB0 0.27313977\n",
      "music:  mPO0 motion : mJB0 -0.00822898\n",
      "music:  mJS0 motion : mJB0 0.15264952\n",
      "music:  mBR3 motion : mJB0 0.057543725\n",
      "music:  mBR4 motion : mJB0 -0.14038682\n",
      "music:  mLH0 motion : mJB0 0.12863988\n",
      "music:  mLO2 motion : mJB0 -0.10100515\n",
      "music:  mKR1 motion : mJB0 0.0504803\n",
      "music:  mLO5 motion : mJB0 0.06902988\n",
      "music:  mMH1 motion : mJB0 0.15503535\n",
      "music:  mPO1 motion : mJB0 0.08475751\n",
      "music:  mJB1 motion : mJB0 0.07236068\n",
      "music:  mHO1 motion : mJB0 0.20598385\n",
      "music:  mWA1 motion : mJB0 0.0021195784\n",
      "music:  mKR0 motion : mJB0 0.11459133\n",
      "music:  mLO4 motion : mJB0 0.048606966\n",
      "music:  mLO3 motion : mJB0 -0.05313343\n",
      "music:  mLH1 motion : mJB0 -0.0067003807\n",
      "music:  mBR5 motion : mJB0 0.023721173\n",
      "music:  mJS1 motion : mJB0 0.15082487\n",
      "music:  mBR2 motion : mJB0 0.04827468\n",
      "music:  mKR4 motion : mJB0 0.064786606\n",
      "music:  mLO0 motion : mJB0 0.0743303\n",
      "music:  mKR3 motion : mJB0 0.11400167\n",
      "music:  mLH5 motion : mJB0 -0.041239526\n",
      "music:  mLH2 motion : mJB0 0.18125895\n",
      "music:  mBR1 motion : mJB0 0.12262667\n",
      "music:  mJS2 motion : mJB0 0.14020596\n",
      "music:  mJS5 motion : mJB0 0.08308457\n",
      "music:  mPO5 motion : mJB0 0.013729736\n",
      "music:  mMH5 motion : mJB0 0.0763317\n",
      "music:  mJB2 motion : mJB0 0.09319343\n",
      "music:  mJB5 motion : mJB0 0.08094703\n",
      "music:  mMH2 motion : mJB0 0.04074858\n",
      "music:  mPO2 motion : mJB0 0.16204931\n",
      "music:  mHO2 motion : mJB0 0.15332726\n",
      "music:  mHO5 motion : mJB0 0.08037922\n",
      "music:  mWA5 motion : mJB0 -0.06384511\n",
      "music:  mWA2 motion : mJB0 -6.400421e-05\n",
      "music:  mJS4 motion : mJB0 0.11413962\n",
      "music:  mBR0 motion : mJB0 0.09918222\n",
      "music:  mJS3 motion : mJB0 -0.03702741\n",
      "music:  mLH3 motion : mJB0 -0.024880381\n",
      "music:  mLH4 motion : mJB0 0.012370635\n",
      "music:  mKR2 motion : mJB0 0.10680305\n",
      "music:  mKR5 motion : mJB0 0.048827533\n",
      "music:  mLO1 motion : mJB0 0.06580298\n",
      "music:  mWA3 motion : mJB0 0.041320518\n",
      "music:  mWA4 motion : mJB0 0.11716397\n",
      "music:  mHO4 motion : mJB0 0.17151248\n",
      "music:  mHO3 motion : mJB0 0.095007926\n",
      "music:  mMH3 motion : mJB0 0.10041989\n",
      "music:  mJB4 motion : mJB0 -0.22994903\n",
      "music:  mPO3 motion : mJB0 0.10835729\n",
      "music:  mPO4 motion : mJB0 -0.19878995\n",
      "music:  mJB3 motion : mJB0 -0.09737246\n",
      "music:  mMH4 motion : mJB0 0.057597905\n"
     ]
    }
   ],
   "source": [
    "indx = 2\n",
    "print(music_encodings_name[indx], [names.index(music_encodings_name[indx])])\n",
    "for i in range(60):\n",
    "    print(\"music: \", music_encodings_name[i] , \"motion :\", names[names.index(music_encodings_name[indx])] , (F.cosine_similarity(music_encodings[i],em_[names.index(music_encodings_name[indx])] , dim=1)).detach().cpu().numpy()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c808b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3f09ae",
   "metadata": {},
   "source": [
    "## Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a3b5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_music import evaluate_music_motion_generative_style, evaluate_music_motion_generative_style2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc8c9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=torch.device('cuda'), jit=False)  # Must set jit=False for training\n",
    "clip_model.eval()\n",
    "for p in clip_model.parameters():\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b9925e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec_style = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_style/var_len_768_768_aist_style.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f0da1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1910/1910 [00:01<00:00, 1009.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aist_ds = VQFullMotionDataset(\"aist\", split = \"train\" , data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" , window_size = -1)\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08123f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([95000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(encodec_style)\n",
    "\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"{os.path.dirname(encodec_style)}/trans_motion.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "25fc87b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genre_dict = {\n",
    "\"mBR\" : \"Break\",\n",
    "\"mPO\" : \"Pop\",\n",
    "\"mLO\" : \"Lock\",\n",
    "\"mMH\" : \"Middle Hip-hop\",\n",
    "\"mLH\" : \"LA style Hip-hop\",\n",
    "\"mHO\" : \"House\",    \n",
    "\"mWA\" : \"Waack\",\n",
    "\"mKR\" : \"Krump\",\n",
    "\"mJS\" : \"Street Jazz\",\n",
    "\"mJB\" : \"Ballet Jazz\",\n",
    "}\n",
    "audio_feature_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/audio_features\"\n",
    "audio_encoding_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f2a17627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getscore(ec,em):\n",
    "    return (F.cosine_similarity(ec,em , dim=1)).detach().cpu().numpy()[0]\n",
    "\n",
    "def get_frequent(similarity_list):\n",
    "    trim = []\n",
    "    for i in similarity_list[:5]:\n",
    "        trim.append(i[:3])\n",
    "    return max(set(trim), key = trim.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "126f192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1910 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i,aist_batch in enumerate(tqdm(aist_loader)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e4aeb3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPO4\n"
     ]
    }
   ],
   "source": [
    "motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "music_name = motion_name.split('_')[-2]\n",
    "print(music_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d79ea2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:00<00:06, 30.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 26.99it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 33.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mBR music most similar to: mJB\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Pop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.02it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:06, 32.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mPO music most similar to: mWA\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.42it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 34.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mLO music most similar to: mJB\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Middle Hip-hop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.70it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 33.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mMH music most similar to: mLO\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  LA style Hip-hop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.78it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 33.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mLH music most similar to: mPO\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  House\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.33it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 33.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mHO music most similar to: mLH\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Waack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.31it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 33.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mWA music most similar to: mPO\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Krump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.43it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:06, 32.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mKR music most similar to: mLH\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Street Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.22it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 32.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mJS music most similar to: mJB\n",
      "M_gPO_sBM_cAll_d11_mPO4_ch06\n",
      "mPO4\n",
      "added:  Ballet Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mPO4 + add mJB music most similar to: mJB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_added_style = []\n",
    "pred_aded_style = []\n",
    "for style_ in genre_dict.values():\n",
    "\n",
    "    style = style_\n",
    "    mot_len = aist_batch[\"motion_lengths\"][0]\n",
    "    motion_name = aist_batch[\"names\"][0]\n",
    "\n",
    "    music_name = motion_name.split('_')[-2]\n",
    "    music_encoding=  np.load(os.path.join(audio_encoding_dir , music_name + \".npy\"))\n",
    "\n",
    "    genre = (genre_dict.get(music_name[:3])) if style is None else style\n",
    "\n",
    "    text = clip.tokenize([genre], truncate=True).cuda()\n",
    "    style_embeddings = clip_model.encode_text(text).cpu().float().reshape(-1) if clip_model is not None else None\n",
    "\n",
    "    print(motion_name)\n",
    "    print(music_name)\n",
    "    print(\"added: \", genre)\n",
    "\n",
    "    seq_len = 200\n",
    "    gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "\n",
    "    gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices.cuda(),\\\n",
    "                                    seq_len=seq_len , \\\n",
    "                                    context = torch.Tensor(music_encoding)[None,...].cuda(), \\\n",
    "                                    context_mask=torch.ones((1 ,music_encoding.shape[0]) , dtype = torch.bool).cuda(), \\\n",
    "                                    style_context = torch.Tensor(style_embeddings.reshape(-1))[None,...].cuda(),\n",
    "\n",
    "                                    )\n",
    "\n",
    "    out_motion = torch.zeros((aist_batch[\"motion\"].shape[0] ,gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "    for i in range(0 , seq_len, 200):\n",
    "        quant , out_motion_= vqvae_model.decode(gen_motion_indices[:,i:i+200])\n",
    "        out_motion[:,i:i+200] = out_motion_\n",
    "\n",
    "    out_motion = out_motion[:,1:]\n",
    "    \n",
    "    em = motion_extractor(out_motion, torch.Tensor([seq_len]))\n",
    "    similarity_name_list  =sorted(music_encodings_name, key= lambda x: getscore(music_encodings[music_encodings_name.index(x)] , em ), reverse = True)\n",
    "    try: \n",
    "        added_music =  list(genre_dict.keys())[list(genre_dict.values()).index(style)]\n",
    "    except:\n",
    "        added_music = None\n",
    "        \n",
    "        \n",
    "    pred_add_music = get_frequent(similarity_name_list)\n",
    "    print( f\"og {music_name} + add {added_music}\" , f\"music most similar to: {pred_add_music}\")\n",
    "    \n",
    "    og_added_style.append(added_music)\n",
    "    pred_aded_style.append(pred_add_music)\n",
    "    \n",
    "cnt = 0\n",
    "for i in range(len(og_added_style)):\n",
    "    cnt+=og_added_style[i]==pred_aded_style[i]\n",
    "cnt/len(og_added_style)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "eb6f4ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bab5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811fa03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "53d3bf52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bdf9bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mJS2 + add mLH music most similar to: mLH ['mJS5', 'mLH1', 'mLH2', 'mMH5', 'mLH4']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495a463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c40965c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og mBR0 + add mBR motion : mLH5 0.22952467\n",
      "og mBR1 + add mBR motion : mLH5 0.31058973\n",
      "og mBR2 + add mBR motion : mLH5 0.36543846\n",
      "og mBR3 + add mBR motion : mLH5 0.34459582\n",
      "og mBR4 + add mBR motion : mLH5 0.17643668\n",
      "og mBR5 + add mBR motion : mLH5 0.3106068\n",
      "og mHO0 + add mBR motion : mLH5 0.24023971\n",
      "og mHO1 + add mBR motion : mLH5 0.30225283\n",
      "og mHO2 + add mBR motion : mLH5 -0.0542868\n",
      "og mHO3 + add mBR motion : mLH5 0.03304533\n",
      "og mHO4 + add mBR motion : mLH5 0.10309335\n",
      "og mHO5 + add mBR motion : mLH5 0.1036674\n",
      "og mJB0 + add mBR motion : mLH5 0.17873418\n",
      "og mJB1 + add mBR motion : mLH5 0.089289896\n",
      "og mJB2 + add mBR motion : mLH5 0.1746877\n",
      "og mJB3 + add mBR motion : mLH5 0.3168804\n",
      "og mJB4 + add mBR motion : mLH5 0.116581395\n",
      "og mJB5 + add mBR motion : mLH5 0.105608374\n",
      "og mJS0 + add mBR motion : mLH5 -0.0076647885\n",
      "og mJS1 + add mBR motion : mLH5 0.4384472\n",
      "og mJS2 + add mBR motion : mLH5 0.12914537\n",
      "og mJS3 + add mBR motion : mLH5 0.35537\n",
      "og mJS4 + add mBR motion : mLH5 0.050492648\n",
      "og mJS5 + add mBR motion : mLH5 0.008540086\n",
      "og mKR0 + add mBR motion : mLH5 0.2841194\n",
      "og mKR1 + add mBR motion : mLH5 0.07918392\n",
      "og mKR2 + add mBR motion : mLH5 0.28384387\n",
      "og mKR3 + add mBR motion : mLH5 0.20455804\n",
      "og mKR4 + add mBR motion : mLH5 -0.3949303\n",
      "og mKR5 + add mBR motion : mLH5 0.08576769\n",
      "og mLH0 + add mBR motion : mLH5 0.23317108\n",
      "og mLH1 + add mBR motion : mLH5 0.14043504\n",
      "og mLH2 + add mBR motion : mLH5 0.400741\n",
      "og mLH3 + add mBR motion : mLH5 0.16116932\n",
      "og mLH4 + add mBR motion : mLH5 0.073710024\n",
      "og mLH5 + add mBR motion : mLH5 0.24093823\n",
      "og mLO0 + add mBR motion : mLH5 0.12721905\n",
      "og mLO1 + add mBR motion : mLH5 0.5199822\n",
      "og mLO2 + add mBR motion : mLH5 0.26437977\n",
      "og mLO3 + add mBR motion : mLH5 0.26949102\n",
      "og mLO4 + add mBR motion : mLH5 0.23521228\n",
      "og mLO5 + add mBR motion : mLH5 -0.023839258\n",
      "og mMH0 + add mBR motion : mLH5 0.25639042\n",
      "og mMH1 + add mBR motion : mLH5 0.22506262\n",
      "og mMH2 + add mBR motion : mLH5 0.24829626\n",
      "og mMH3 + add mBR motion : mLH5 0.37927872\n",
      "og mMH4 + add mBR motion : mLH5 0.1275083\n",
      "og mMH5 + add mBR motion : mLH5 0.62636137\n",
      "og mPO0 + add mBR motion : mLH5 0.17294943\n",
      "og mPO1 + add mBR motion : mLH5 0.31920132\n",
      "og mPO2 + add mBR motion : mLH5 0.34594613\n",
      "og mPO3 + add mBR motion : mLH5 0.1609236\n",
      "og mPO4 + add mBR motion : mLH5 0.22941293\n",
      "og mPO5 + add mBR motion : mLH5 0.115169615\n",
      "og mWA0 + add mBR motion : mLH5 0.061971392\n",
      "og mWA1 + add mBR motion : mLH5 0.19194508\n",
      "og mWA2 + add mBR motion : mLH5 -0.056549534\n",
      "og mWA3 + add mBR motion : mLH5 0.17873895\n",
      "og mWA4 + add mBR motion : mLH5 -0.1686614\n",
      "og mWA5 + add mBR motion : mLH5 -0.016412519\n"
     ]
    }
   ],
   "source": [
    "for i in indxs:\n",
    "    print(\"music: \", music_encodings_name[i] , \"motion :\", music_name, (F.cosine_similarity(music_encodings[i],em , dim=1)).detach().cpu().numpy()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16682a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43e7d98b",
   "metadata": {},
   "source": [
    "## Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7d88160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a2cfcc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodec = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist/var_len_768_768_aist.yaml\"\n",
    "encodec_sine = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_sine_aist/var_len_768_768_sine_aist.yaml\"\n",
    "librosa = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_35/var_len_768_768_aist_35.yaml\"\n",
    "encodec_prob50 = \"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/generator/var_len/trans_768_768_albi_aist_mask_prob50/trans_768_768_albi_aist_mask_prob50.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1fb9a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([210000.])\n"
     ]
    }
   ],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "trans_option = \"encodec\"\n",
    "\n",
    "cfg_trans = get_cfg_defaults()\n",
    "cfg_trans.merge_from_file(encodec)\n",
    "\n",
    "\n",
    "trans_model = MotionRegressorModel(args = cfg_trans.motion_trans,pad_value=1025 ).eval()\n",
    "pkg_trans = torch.load(f\"{os.path.dirname(encodec)}/trans_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg_trans[\"steps\"])\n",
    "trans_model.load_state_dict(pkg_trans[\"model\"])\n",
    "trans_model =trans_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "14e48d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.models.vqvae import VQMotionModel\n",
    "from core.models.motion_regressor import MotionRegressorModel\n",
    "\n",
    "\n",
    "cfg_vq = get_cfg_defaults()\n",
    "cfg_vq.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/configs/var_len_768_768_aist_vq.yaml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93493692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([295000.])\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = VQMotionModel(cfg_vq.vqvae).eval()\n",
    "pkg = torch.load(f\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/var_len/vq_768_768_mix/vqvae_motion_best_fid.pt\", map_location = 'cpu')\n",
    "print(pkg[\"steps\"])\n",
    "vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "vqvae_model =vqvae_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17431c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6451f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7b7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "048ea1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.evaluator_wrapper import AISTEvaluatorModelWrapper\n",
    "from utils.eval_music import evaluate_music_motion_generative_extractors\n",
    "from utils.eval_trans import calculate_R_precision,calculate_activation_statistics,calculate_diversity,calculate_frechet_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "768c0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "\n",
    "cfg_eval = get_cfg_defaults()\n",
    "cfg_eval.merge_from_file(\"/srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/extractors/big/aist_extractor.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "f92e62fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 784.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.evaluator_dataset import EvaluatorMotionCollator, EvaluatorVarLenMotionDataset, EvaluatorMotionDataset\n",
    "aist_ds = EvaluatorMotionDataset(split = \"test\" ,data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" ,window_size = -1 )\n",
    "collate_fn = EvaluatorMotionCollator()\n",
    "\n",
    "aist_loader = DATALoader(aist_ds,20,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "35623783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from:  /srv/scratch/sanisetty3/music_motion/motion_vqvae/checkpoints/extractors/big/extractors.pt steps:  tensor([95000.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "aist_evaluator = AISTEvaluatorModelWrapper(cfg_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "fce91145",
   "metadata": {},
   "outputs": [],
   "source": [
    "fids = []\n",
    "div_R = []\n",
    "div_p = []\n",
    "\n",
    "for i in range(20):\n",
    "    fid, diversity_real, diversity = evaluate_music_motion_generative_extractors(aist_loader , vqvae_model= vqvae_model ,net = trans_model, eval_wrapper = aist_evaluator, seq_len = 600)\n",
    "    fids.append(fid)\n",
    "    div_R.append(diversity_real)\n",
    "    div_p.apppend(diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd430534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "c8b8c62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:04<00:00, 53.21it/s]\n",
      "100%|██████████| 141/141 [00:02<00:00, 54.95it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 53.76it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 54.11it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 53.46it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 53.68it/s]\n",
      "100%|██████████| 141/141 [00:02<00:00, 53.69it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 53.30it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 53.53it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 53.24it/s]\n",
      "100%|██████████| 141/141 [00:02<00:00, 53.22it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 53.63it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 53.06it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 53.26it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 53.34it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 51.33it/s]\n",
      "100%|██████████| 141/141 [00:03<00:00, 35.45it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 53.76it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 53.87it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 54.31it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 52.91it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 53.02it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 52.91it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 53.76it/s]\n",
      "100%|██████████| 159/159 [00:02<00:00, 53.13it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 54.15it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 53.37it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 54.32it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 53.33it/s]\n",
      "100%|██████████| 213/213 [00:04<00:00, 53.14it/s]\n",
      "100%|██████████| 147/147 [00:02<00:00, 53.08it/s]\n",
      "100%|██████████| 213/213 [00:03<00:00, 53.37it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 53.80it/s]\n",
      "100%|██████████| 239/239 [00:04<00:00, 53.57it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 53.28it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 53.23it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 53.58it/s]\n",
      "100%|██████████| 191/191 [00:03<00:00, 52.97it/s]\n",
      "100%|██████████| 213/213 [00:04<00:00, 53.06it/s]\n",
      "100%|██████████| 174/174 [00:03<00:00, 53.55it/s]\n",
      "100%|██████████| 2/2 [02:22<00:00, 71.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid  0.6284469415386564\n",
      "1.1949672 1.1772099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seq_len = 600\n",
    "motion_annotation_list = []\n",
    "motion_pred_list = []\n",
    "\n",
    "music_annotation_list = []\n",
    "music_pred_list = []\n",
    "\n",
    "R_precision_real = 0\n",
    "R_precision = 0\n",
    "\n",
    "nb_sample = 0\n",
    "\n",
    "audio_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "\n",
    "matching_score_real = 0\n",
    "matching_score_pred = 0\n",
    "motion_extractor = motion_extractor.cuda()\n",
    "music_extractor = music_extractor.cuda()\n",
    "\n",
    "for j,aist_batch in enumerate(tqdm(aist_loader)):\n",
    "    \n",
    "#     if j>3:\n",
    "#         break\n",
    "    \n",
    "    bs, seq = aist_batch[\"motion\"].shape[0], aist_batch[\"motion\"].shape[1]\n",
    "    \n",
    "    em = motion_extractor(aist_batch[\"motion\"].cuda(), aist_batch[\"motion_lengths\"].cuda())\n",
    "    et = music_extractor(aist_batch[\"condition\"].cuda(),aist_batch[\"motion_lengths\"].cuda())\n",
    "    \n",
    "    generated_motion = torch.zeros(aist_batch[\"motion\"].shape).cuda()\n",
    "    \n",
    "    for i in range(bs):\n",
    "        \n",
    "        mot_len = int(aist_batch[\"motion_lengths\"][i])\n",
    "        motion_name = aist_batch[\"names\"][i]\n",
    "\n",
    "        music_name = motion_name.split('_')[-2]\n",
    "        music_encoding=  np.load(os.path.join(audio_dir , music_name + \".npy\"))\n",
    "\n",
    "        music_name = motion_name.split('_')[-2]\n",
    "        gen_motion_indices = torch.randint(0 , 1024 , (1,1))\n",
    "\n",
    "        gen_motion_indices = trans_model.generate(start_tokens =gen_motion_indices.cuda(),\\\n",
    "                                                    seq_len=mot_len , \\\n",
    "                                                    context = torch.Tensor(music_encoding)[None,...].cuda(), \\\n",
    "                                                    context_mask=torch.ones((1 ,music_encoding.shape[0]) , dtype = torch.bool).cuda()\n",
    "                                                    )\n",
    "\n",
    "\n",
    "        out_motion = torch.zeros((1, gen_motion_indices.shape[-1] , aist_batch[\"motion\"].shape[-1]))\n",
    "        for j in range(0 , mot_len, 200):\n",
    "            quant , out_motion_= vqvae_model.decode(gen_motion_indices[:,j:j+200])\n",
    "            out_motion[:,j:j+200] = out_motion_\n",
    "            \n",
    "        generated_motion[i:i+1,:mot_len,:] = out_motion[:,1:,:]\n",
    "        \n",
    "#         print(out_motion.shape)\n",
    "        \n",
    "\n",
    "    em_pred = motion_extractor(generated_motion.cuda(), aist_batch[\"motion_lengths\"].cuda())\n",
    "    et_pred = music_extractor(aist_batch[\"condition\"].cuda(),aist_batch[\"motion_lengths\"].cuda())\n",
    "    \n",
    "\n",
    "\n",
    "    motion_pred_list.append(em_pred)\n",
    "    motion_annotation_list.append(em)\n",
    "\n",
    "    music_pred_list.append(et_pred)\n",
    "    music_annotation_list.append(et)\n",
    "    \n",
    "    \n",
    "    temp_R, temp_match = calculate_R_precision(et.detach().cpu().numpy(), em.detach().cpu().numpy(), top_k=3, sum_all=True)\n",
    "    R_precision_real += temp_R\n",
    "    matching_score_real += temp_match\n",
    "\n",
    "    temp_R_pred, temp_match_pred = calculate_R_precision(et_pred.detach().cpu().numpy(), em_pred.detach().cpu().numpy(), top_k=3, sum_all=True)\n",
    "    R_precision += temp_R_pred\n",
    "    matching_score_pred += temp_match_pred\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    nb_sample += bs\n",
    "    \n",
    "motion_annotation_np = torch.cat(motion_annotation_list, dim=0).detach().cpu().numpy()\n",
    "motion_pred_np = torch.cat(motion_pred_list, dim=0).detach().cpu().numpy()\n",
    "\n",
    "music_annotation_np = torch.cat(music_annotation_list, dim=0).detach().cpu().numpy()\n",
    "music_pred_np = torch.cat(music_pred_list, dim=0).detach().cpu().numpy()\n",
    "\n",
    "gt_mu, gt_cov  = calculate_activation_statistics(motion_annotation_np)\n",
    "mu, cov= calculate_activation_statistics(motion_pred_np)\n",
    "fid = calculate_frechet_distance(gt_mu, gt_cov, mu, cov)\n",
    "print(\"fid \", fid)\n",
    "\n",
    "diversity_real = calculate_diversity(motion_annotation_np, 100 if nb_sample > 100 else 10)\n",
    "diversity = calculate_diversity(motion_pred_np, 100 if nb_sample > 100 else 10)\n",
    "print(diversity_real , diversity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "a5fe441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid  0.6284469415386564\n",
      "1.1452008 1.1187509\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "motion_annotation_np = torch.cat(motion_annotation_list, dim=0).detach().cpu().numpy()\n",
    "motion_pred_np = torch.cat(motion_pred_list, dim=0).detach().cpu().numpy()\n",
    "\n",
    "music_annotation_np = torch.cat(music_annotation_list, dim=0).detach().cpu().numpy()\n",
    "music_pred_np = torch.cat(music_pred_list, dim=0).detach().cpu().numpy()\n",
    "\n",
    "gt_mu, gt_cov  = calculate_activation_statistics(motion_annotation_np)\n",
    "mu, cov= calculate_activation_statistics(motion_pred_np)\n",
    "fid = calculate_frechet_distance(gt_mu, gt_cov, mu, cov)\n",
    "print(\"fid \", fid)\n",
    "\n",
    "diversity_real = calculate_diversity(motion_annotation_np, 100 if nb_sample > 100 else 30)\n",
    "diversity = calculate_diversity(motion_pred_np, 100 if nb_sample > 100 else 30)\n",
    "print(diversity_real , diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "79b10fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 64)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_annotation_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "1652b9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.075 0.1   0.1  ]\n",
      "[0.05  0.125 0.175]\n",
      "2.016997146606445\n",
      "2.1148876190185546\n"
     ]
    }
   ],
   "source": [
    "print(R_precision_real/motion_annotation_np.shape[0])\n",
    "print(R_precision/motion_annotation_np.shape[0])\n",
    "\n",
    "print(matching_score_real/motion_annotation_np.shape[0])\n",
    "print(matching_score_pred/motion_annotation_np.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "2ca8d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025 0.05  0.1  ] 2.016996955871582\n",
      "[0.    0.05  0.075] 2.1148876190185546\n"
     ]
    }
   ],
   "source": [
    "ln = music_annotation_np.shape[0]\n",
    "temp_R, temp_match = calculate_R_precision(music_annotation_np, motion_annotation_np, top_k=3, sum_all=True)\n",
    "print(temp_R/ln, temp_match/ln)\n",
    "temp_R_pred, temp_match_pred = calculate_R_precision(music_annotation_np,motion_pred_np, top_k=3, sum_all=True)\n",
    "print(temp_R_pred/ln, temp_match_pred/ln )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6cc89",
   "metadata": {},
   "source": [
    "## Eval on EDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5fecf356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.spatial.transform import Rotation as R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a8aa2704",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_motions = glob(\"/srv/scratch/sanisetty3/music_motion/EDGE/eval/hml/new_joint_vecs/*.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3bd75b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_motions = glob(\"/srv/scratch/sanisetty3/music_motion/EDGE/eval/motions/*.pkl\")\n",
    "aist_motions = glob(\"/srv/scratch/sanisetty3/clean/mint/evals/eval60/g*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252d67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "328c63db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mKR2',\n",
       " 'mWA0',\n",
       " 'mPO1',\n",
       " 'mHO5',\n",
       " 'mLO2',\n",
       " 'mJB5',\n",
       " 'mLH4',\n",
       " 'mBR0',\n",
       " 'mMH3',\n",
       " 'mJS3']"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "c6649d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mBR0', 'mHO5', 'mJS3', 'mKR2', 'mLH4', 'mLO2', 'mMH3', 'mPO1', 'mWA0'}"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(names) & set([i.split(\".\")[0][-4:] for i in edge_motions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "61ef0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hml_msc = ['mBR0', 'mHO5', 'mJS3', 'mKR2', 'mLH4', 'mLO2', 'mMH3', 'mPO1', 'mWA0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "99083473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([899, 263])"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.load(f\"/srv/scratch/sanisetty3/music_motion/EDGE/eval/hml/new_joint_vecs/{music_name}.npy\")).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "903ad259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 809.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from core.datasets.evaluator_dataset import EvaluatorMotionCollator, EvaluatorVarLenMotionDataset, EvaluatorMotionDataset\n",
    "aist_ds = EvaluatorMotionDataset(split = \"test\" ,data_root = \"/srv/scratch/sanisetty3/music_motion/AIST\" ,window_size = -1 )\n",
    "collate_fn = EvaluatorMotionCollator()\n",
    "\n",
    "aist_loader = DATALoader(aist_ds,1,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "2f7e3c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:00<00:00, 59.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mKR2\n",
      "mPO1\n",
      "mLH4\n",
      "mWA0\n",
      "mJS3\n",
      "mMH3\n",
      "mKR2\n",
      "mHO5\n",
      "mBR0\n",
      "mMH3\n",
      "mHO5\n",
      "mMH3\n",
      "mJS3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:00<00:00, 65.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mLH4\n",
      "mJB5\n",
      "mKR2\n",
      "mWA0\n",
      "mLH4\n",
      "mHO5\n",
      "mJB5\n",
      "mJB5\n",
      "mJB5\n",
      "mPO1\n",
      "mLH4\n",
      "mLO2\n",
      "mMH3\n",
      "mLO2\n",
      "mJS3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [00:00<00:00, 58.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPO1\n",
      "mBR0\n",
      "mLO2\n",
      "mPO1\n",
      "mWA0\n",
      "mKR2\n",
      "mHO5\n",
      "mBR0\n",
      "mJS3\n",
      "mLO2\n",
      "mBR0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 60.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mWA0\n",
      "fid  1.6043953599870409\n",
      "1.1438 0.49290603\n",
      "[1 2 4] 71.93391\n",
      "[1 2 3] 82.030975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seq_len = 600\n",
    "motion_annotation_list = []\n",
    "motion_pred_list = []\n",
    "\n",
    "music_annotation_list = []\n",
    "music_pred_list = []\n",
    "\n",
    "R_precision_real = 0\n",
    "R_precision = 0\n",
    "\n",
    "nb_sample = 0\n",
    "\n",
    "audio_dir = \"/srv/scratch/sanisetty3/music_motion/AIST/music\"\n",
    "\n",
    "matching_score_real = 0\n",
    "matching_score_pred = 0\n",
    "motion_extractor = motion_extractor.cuda()\n",
    "music_extractor = music_extractor.cuda()\n",
    "\n",
    "for j,aist_batch in enumerate(tqdm(aist_loader)):\n",
    "    \n",
    "#     if j>3:\n",
    "#         break\n",
    "    \n",
    "    bs, seq = aist_batch[\"motion\"].shape[0], aist_batch[\"motion\"].shape[1]\n",
    "    \n",
    "    \n",
    "    mot_len = int(aist_batch[\"motion_lengths\"][0])\n",
    "\n",
    "    em = motion_extractor(aist_batch[\"motion\"].cuda(), aist_batch[\"motion_lengths\"].cuda())\n",
    "    et = music_extractor(aist_batch[\"condition\"].cuda(),aist_batch[\"motion_lengths\"].cuda())\n",
    "    \n",
    "    motion_name = aist_batch[\"names\"][0]\n",
    "    \n",
    "    music_name = motion_name.split('_')[-2]\n",
    "    print(music_name)\n",
    "    music_encoding=  np.load(os.path.join(audio_dir , music_name + \".npy\"))\n",
    "    \n",
    "\n",
    "    try:\n",
    "        generated_motion = torch.Tensor(np.load(f\"/srv/scratch/sanisetty3/music_motion/EDGE/eval/hml/new_joint_vecs/{music_name}.npy\"))[:mot_len,:][None,...]\n",
    "    except:\n",
    "        continue\n",
    "                                   \n",
    "\n",
    "    em_pred = motion_extractor(generated_motion.cuda(), aist_batch[\"motion_lengths\"].cuda())\n",
    "    et_pred = music_extractor(aist_batch[\"condition\"].cuda(),aist_batch[\"motion_lengths\"].cuda())\n",
    "    \n",
    "\n",
    "\n",
    "    motion_pred_list.append(em_pred)\n",
    "    motion_annotation_list.append(em)\n",
    "\n",
    "    music_pred_list.append(et_pred)\n",
    "    music_annotation_list.append(et)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nb_sample += bs\n",
    "    \n",
    "motion_annotation_np = torch.cat(motion_annotation_list, dim=0).detach().cpu().numpy()\n",
    "motion_pred_np = torch.cat(motion_pred_list, dim=0).detach().cpu().numpy()\n",
    "\n",
    "music_annotation_np = torch.cat(music_annotation_list, dim=0).detach().cpu().numpy()\n",
    "music_pred_np = torch.cat(music_pred_list, dim=0).detach().cpu().numpy()\n",
    "\n",
    "gt_mu, gt_cov  = calculate_activation_statistics(motion_annotation_np)\n",
    "mu, cov= calculate_activation_statistics(motion_pred_np)\n",
    "fid = calculate_frechet_distance(gt_mu, gt_cov, mu, cov)\n",
    "print(\"fid \", fid)\n",
    "\n",
    "diversity_real = calculate_diversity(motion_annotation_np, 100 if nb_sample > 100 else 10)\n",
    "diversity = calculate_diversity(motion_pred_np, 100 if nb_sample > 100 else 10)\n",
    "print(diversity_real , diversity)\n",
    "\n",
    "\n",
    "temp_R, temp_match = calculate_R_precision(music_annotation_np, motion_annotation_np, top_k=3, sum_all=True)\n",
    "print(temp_R, temp_match)\n",
    "temp_R_pred, temp_match_pred = calculate_R_precision(music_pred_np,motion_pred_np, top_k=3, sum_all=True)\n",
    "print(temp_R_pred, temp_match_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "b7167a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 64)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_annotation_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d484f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68dbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80854a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36610b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4140726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8a2d9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smplx import SMPL\n",
    "\n",
    "# set smpl\n",
    "smpl = SMPL(model_path=\"/srv/share/datasets/AIST/smpl_models\", gender='MALE', batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2221b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aist_plusplus.loader import AISTDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c1cc52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_motions = glob(\"/srv/scratch/sanisetty3/music_motion/EDGE/eval/motions/*.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2de33e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = \"/srv/share/datasets/AIST/aist_plusplus_final/\"\n",
    "audio_dir = \"/srv/share/datasets/AIST/aist_plusplus_media/audio/wav/\"\n",
    "audio_cache_dir = \"/srv/scratch/sanisetty3/clean/mint/data/audio_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83f608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "492a5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_names = []\n",
    "seq_names += np.loadtxt(\n",
    "            os.path.join(\"/srv/scratch/sanisetty3/mint_pyt/mint/third_party/aist_plusplus_final/splits/crossmodal_test.txt\"), dtype=str\n",
    "        ).tolist()\n",
    "\n",
    "ignore_list = np.loadtxt(\n",
    "    os.path.join(\"/srv/scratch/sanisetty3/mint_pyt/mint/third_party/aist_plusplus_final/\", \"ignore_list.txt\"), dtype=str\n",
    ").tolist()\n",
    "seq_names = [name for name in seq_names if name not in ignore_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e3b7d310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "dd36043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cache_audio_features(seq_names):\n",
    "    FPS = 60\n",
    "    HOP_LENGTH = 512\n",
    "    SR = FPS * HOP_LENGTH\n",
    "    EPS = 1e-6\n",
    "\n",
    "    def _get_tempo(audio_name):\n",
    "        \"\"\"Get tempo (BPM) for a music by parsing music name.\"\"\"\n",
    "        assert len(audio_name) == 4\n",
    "        if audio_name[0:3] in ['mBR', 'mPO', 'mLO', 'mMH', 'mLH', 'mWA', 'mKR', 'mJS', 'mJB']:\n",
    "            return int(audio_name[3]) * 10 + 80\n",
    "        elif audio_name[0:3] == 'mHO':\n",
    "            return int(audio_name[3]) * 5 + 110\n",
    "        else: assert False, audio_name\n",
    "\n",
    "    audio_names = list(set([seq_name.split(\"_\")[-2] for seq_name in seq_names]))\n",
    "    print(audio_names)\n",
    "\n",
    "    for audio_name in audio_names:\n",
    "        save_path = os.path.join(\"/srv/scratch/sanisetty3/clean/mint/data/audio_cache\", f\"{audio_name}.npy\")\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        data, _ = librosa.load(os.path.join(audio_dir, f\"{audio_name}.wav\"), sr=SR)\n",
    "        envelope = librosa.onset.onset_strength(data, sr=SR)  # (seq_len,)\n",
    "        mfcc = librosa.feature.mfcc(data, sr=SR, n_mfcc=20).T  # (seq_len, 20)\n",
    "        chroma = librosa.feature.chroma_cens(\n",
    "            data, sr=SR, hop_length=HOP_LENGTH, n_chroma=12).T  # (seq_len, 12)\n",
    "\n",
    "        peak_idxs = librosa.onset.onset_detect(\n",
    "            onset_envelope=envelope.flatten(), sr=SR, hop_length=HOP_LENGTH)\n",
    "        peak_onehot = np.zeros_like(envelope, dtype=np.float32)\n",
    "        peak_onehot[peak_idxs] = 1.0  # (seq_len,)\n",
    "\n",
    "        tempo, beat_idxs = librosa.beat.beat_track(\n",
    "            onset_envelope=envelope, sr=SR, hop_length=HOP_LENGTH,\n",
    "            start_bpm=_get_tempo(audio_name), tightness=100)\n",
    "        beat_onehot = np.zeros_like(envelope, dtype=np.float32)\n",
    "        beat_onehot[beat_idxs] = 1.0  # (seq_len,)\n",
    "\n",
    "        audio_feature = np.concatenate([\n",
    "            envelope[:, None], mfcc, chroma, peak_onehot[:, None], beat_onehot[:, None]\n",
    "        ], axis=-1)\n",
    "        np.save(save_path, audio_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ee55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mKR2', 'mWA0', 'mPO1', 'mHO5', 'mLO2', 'mJB5', 'mLH4', 'mBR0', 'mMH3', 'mJS3']\n"
     ]
    }
   ],
   "source": [
    "cache_audio_features(seq_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd16de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a4ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "03e73cdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-088030e97ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmpl_poses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"smpl_poses\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msmpl_trans\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"smpl_trans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source_file' is not defined"
     ]
    }
   ],
   "source": [
    "with open(source_file, \"rb\") as fp:\n",
    "        data = pickle.load(fp)\n",
    "    \n",
    "smpl_poses = data[\"smpl_poses\"]\n",
    "smpl_trans =  data[\"smpl_trans\"]\n",
    "\n",
    "smpl_poses_ = R.from_rotvec(smpl_poses.reshape(-1, 3)).as_matrix().reshape(smpl_poses.shape[0], -1)\n",
    "motion_sequence = np.concatenate([smpl_trans, smpl_poses_], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "644e7560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6b48e40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "1190076a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e24ae61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = \"/srv/share/datasets/AIST/aist_plusplus_final/\"\n",
    "audio_dir = \"/srv/share/datasets/AIST/aist_plusplus_media/audio/wav/\"\n",
    "audio_cache_dir = \"/srv/scratch/sanisetty3/clean/mint/data/audio_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "97704cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye(n, batch_shape):\n",
    "    iden = np.zeros(np.concatenate([batch_shape, [n, n]]))\n",
    "    iden[..., 0, 0] = 1.0\n",
    "    iden[..., 1, 1] = 1.0\n",
    "    iden[..., 2, 2] = 1.0\n",
    "    return iden\n",
    "\n",
    "\n",
    "def get_closest_rotmat(rotmats):\n",
    "    \"\"\"\n",
    "    Finds the rotation matrix that is closest to the inputs in terms of the Frobenius norm. For each input matrix\n",
    "    it computes the SVD as R = USV' and sets R_closest = UV'. Additionally, it is made sure that det(R_closest) == 1.\n",
    "    Args:\n",
    "        rotmats: np array of shape (..., 3, 3).\n",
    "    Returns:\n",
    "        A numpy array of the same shape as the inputs.\n",
    "    \"\"\"\n",
    "    u, s, vh = np.linalg.svd(rotmats)\n",
    "    r_closest = np.matmul(u, vh)\n",
    "\n",
    "    # if the determinant of UV' is -1, we must flip the sign of the last column of u\n",
    "    det = np.linalg.det(r_closest)  # (..., )\n",
    "    iden = eye(3, det.shape)\n",
    "    iden[..., 2, 2] = np.sign(det)\n",
    "    r_closest = np.matmul(np.matmul(u, iden), vh)\n",
    "    return r_closest\n",
    "\n",
    "\n",
    "def recover_to_axis_angles(motion):\n",
    "    batch_size, seq_len, dim = motion.shape\n",
    "    assert dim == 225\n",
    "    transl = motion[:, :, 6:9]\n",
    "    rotmats = get_closest_rotmat(\n",
    "        np.reshape(motion[:, :, 9:], (batch_size, seq_len, 24, 3, 3))\n",
    "    )\n",
    "    axis_angles = R.from_matrix(\n",
    "        rotmats.reshape(-1, 3, 3)\n",
    "    ).as_rotvec().reshape(batch_size, seq_len, 24, 3)\n",
    "    return axis_angles, transl\n",
    "\n",
    "\n",
    "def recover_motion_to_keypoints(motion, smpl_model):\n",
    "    smpl_poses, smpl_trans = recover_to_axis_angles(motion)\n",
    "    smpl_poses = np.squeeze(smpl_poses, axis=0)  # (seq_len, 24, 3)\n",
    "    smpl_trans = np.squeeze(smpl_trans, axis=0)  # (seq_len, 3)\n",
    "    keypoints3d = smpl_model.forward(\n",
    "        global_orient=torch.from_numpy(smpl_poses[:, 0:1]).float(),\n",
    "        body_pose=torch.from_numpy(smpl_poses[:, 1:]).float(),\n",
    "        transl=torch.from_numpy(smpl_trans).float(),\n",
    "    ).joints.detach().numpy()[:, :24, :]   # (seq_len, 24, 3)\n",
    "    return keypoints3d\n",
    "\n",
    "\n",
    "def motion_peak_onehot(joints):\n",
    "    \"\"\"Calculate motion beats.\n",
    "    Kwargs:\n",
    "        joints: [nframes, njoints, 3]\n",
    "    Returns:\n",
    "        - peak_onhot: motion beats.\n",
    "    \"\"\"\n",
    "    # Calculate velocity.\n",
    "    velocity = np.zeros_like(joints, dtype=np.float32)\n",
    "    velocity[1:] = joints[1:] - joints[:-1]\n",
    "    velocity_norms = np.linalg.norm(velocity, axis=2)\n",
    "    envelope = np.sum(velocity_norms, axis=1)  # (seq_len,)\n",
    "\n",
    "    # Find local minima in velocity -- beats\n",
    "    peak_idxs = scisignal.argrelextrema(envelope, np.less, axis=0, order=10) # 10 for 60FPS\n",
    "    peak_onehot = np.zeros_like(envelope, dtype=bool)\n",
    "    peak_onehot[peak_idxs] = 1\n",
    "\n",
    "    # # Second-derivative of the velocity shows the energy of the beats\n",
    "    # peak_energy = np.gradient(np.gradient(envelope)) # (seq_len,)\n",
    "    # # optimize peaks\n",
    "    # peak_onehot[peak_energy<0.001] = 0\n",
    "    return peak_onehot\n",
    "\n",
    "\n",
    "def alignment_score(music_beats, motion_beats, sigma=3):\n",
    "    \"\"\"Calculate alignment score between music and motion.\"\"\"\n",
    "    if motion_beats.sum() == 0:\n",
    "        return 0.0\n",
    "    music_beat_idxs = np.where(music_beats)[0]\n",
    "    motion_beat_idxs = np.where(motion_beats)[0]\n",
    "    score_all = []\n",
    "    for motion_beat_idx in motion_beat_idxs:\n",
    "        dists = np.abs(music_beat_idxs - motion_beat_idx).astype(np.float32)\n",
    "        ind = np.argmin(dists)\n",
    "        score = np.exp(- dists[ind]**2 / 2 / sigma**2)\n",
    "        score_all.append(score)\n",
    "    return sum(score_all) / len(score_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c2a36d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1 / 20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scisignal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-815bbecca7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtransl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmpl_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ).joints.detach().numpy()[:, :24, :]   # (seq_len, 24, 3)\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmotion_beats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmotion_peak_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# get real data music beats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0maudio_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-0551d1e1454a>\u001b[0m in \u001b[0;36mmotion_peak_onehot\u001b[0;34m(joints)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Find local minima in velocity -- beats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mpeak_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscisignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margrelextrema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvelope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 10 for 60FPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mpeak_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvelope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mpeak_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeak_idxs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scisignal' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = AISTDataset(anno_dir)\n",
    "n_samples = len(seq_names)\n",
    "beat_scores = []\n",
    "for i, seq_name in enumerate(seq_names):\n",
    "    print(\"processing %d / %d\" % (i + 1, n_samples))\n",
    "    # get real data motion beats\n",
    "    smpl_poses, smpl_scaling, smpl_trans = AISTDataset.load_motion(\n",
    "        dataset.motion_dir, seq_name)\n",
    "    smpl_trans /= smpl_scaling\n",
    "    keypoints3d = smpl.forward(\n",
    "        global_orient=torch.from_numpy(smpl_poses[:, 0:1]).float(),\n",
    "        body_pose=torch.from_numpy(smpl_poses[:, 1:]).float(),\n",
    "        transl=torch.from_numpy(smpl_trans).float(),\n",
    "    ).joints.detach().numpy()[:, :24, :]   # (seq_len, 24, 3)\n",
    "    motion_beats = motion_peak_onehot(keypoints3d)\n",
    "    # get real data music beats\n",
    "    audio_name = seq_name.split(\"_\")[4]\n",
    "    audio_feature = np.load(os.path.join(audio_cache_dir, f\"{audio_name}.npy\"))\n",
    "    audio_beats = audio_feature[:keypoints3d.shape[0], -1] # last dim is the music beats\n",
    "    # get beat alignment scores\n",
    "    beat_score = alignment_score(audio_beats, motion_beats, sigma=3)\n",
    "    beat_scores.append(beat_score)\n",
    "print (\"\\nBeat score on real data: %.3f\\n\" % (sum(beat_scores) / n_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbee13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c8e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "bbb4d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aist(aist_vec):\n",
    "    aist_ex = torch.Tensor(aist_vec)\n",
    "    trans = aist_ex[:,:3]\n",
    "    aist_ex_9d = aist_ex[:,3:].reshape(aist_vec.shape[0],24,3,3)\n",
    "    aist_ex_9d[:,-2:] = torch.zeros((aist_vec.shape[0], 2, 3, 3))\n",
    "    global_orient = aist_ex_9d[:, 0:1]\n",
    "    rotations = aist_ex_9d[:, 1:]\n",
    "    out_aist_og = smpl_model(body_pose=rotations, global_orient=global_orient, transl = trans)\n",
    "    \n",
    "            \n",
    "    return  out_aist_og\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "1df07b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = process_aist(smpl_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "cf266d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertices': tensor([[[ 0.6551, -0.0735,  2.6354],\n",
       "          [ 0.6521, -0.0824,  2.6211],\n",
       "          [ 0.6559, -0.0690,  2.6174],\n",
       "          ...,\n",
       "          [ 0.4940, -0.0758,  2.5989],\n",
       "          [ 0.4952, -0.0773,  2.6004],\n",
       "          [ 0.4945, -0.0811,  2.5978]],\n",
       " \n",
       "         [[ 0.6392, -0.0803,  2.6505],\n",
       "          [ 0.6365, -0.0893,  2.6363],\n",
       "          [ 0.6404, -0.0759,  2.6326],\n",
       "          ...,\n",
       "          [ 0.4787, -0.0826,  2.6107],\n",
       "          [ 0.4798, -0.0841,  2.6121],\n",
       "          [ 0.4792, -0.0879,  2.6096]],\n",
       " \n",
       "         [[ 0.6277, -0.0911,  2.6582],\n",
       "          [ 0.6250, -0.1000,  2.6440],\n",
       "          [ 0.6294, -0.0868,  2.6404],\n",
       "          ...,\n",
       "          [ 0.4678, -0.0867,  2.6159],\n",
       "          [ 0.4688, -0.0883,  2.6173],\n",
       "          [ 0.4681, -0.0920,  2.6147]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0608, -0.0188,  2.6868],\n",
       "          [-0.0655, -0.0282,  2.6726],\n",
       "          [-0.0531, -0.0208,  2.6695],\n",
       "          ...,\n",
       "          [-0.1725,  0.0707,  2.6069],\n",
       "          [-0.1730,  0.0690,  2.6086],\n",
       "          [-0.1753,  0.0660,  2.6063]],\n",
       " \n",
       "         [[-0.0522, -0.0297,  2.6782],\n",
       "          [-0.0570, -0.0381,  2.6631],\n",
       "          [-0.0445, -0.0308,  2.6605],\n",
       "          ...,\n",
       "          [-0.1627,  0.0651,  2.6029],\n",
       "          [-0.1631,  0.0631,  2.6044],\n",
       "          [-0.1654,  0.0603,  2.6020]],\n",
       " \n",
       "         [[-0.0456, -0.0338,  2.6737],\n",
       "          [-0.0504, -0.0421,  2.6584],\n",
       "          [-0.0381, -0.0345,  2.6558],\n",
       "          ...,\n",
       "          [-0.1580,  0.0597,  2.6006],\n",
       "          [-0.1585,  0.0576,  2.6020],\n",
       "          [-0.1606,  0.0549,  2.5996]]]),\n",
       " 'vibe': tensor([[[ 6.3225e-01, -1.2746e-01,  2.5481e+00],\n",
       "          [ 5.2309e-01,  1.7635e-02,  2.4659e+00],\n",
       "          [ 3.3601e-01,  4.0470e-02,  2.4177e+00],\n",
       "          ...,\n",
       "          [ 5.9090e-01, -1.2385e-01,  2.5936e+00],\n",
       "          [ 6.1263e-01,  1.3768e-02,  2.5801e+00],\n",
       "          [ 4.9535e-01, -7.3878e-02,  2.5889e+00]],\n",
       " \n",
       "         [[ 6.1815e-01, -1.3474e-01,  2.5635e+00],\n",
       "          [ 5.1162e-01,  1.1414e-02,  2.4795e+00],\n",
       "          [ 3.2628e-01,  3.6222e-02,  2.4357e+00],\n",
       "          ...,\n",
       "          [ 5.7574e-01, -1.3066e-01,  2.6081e+00],\n",
       "          [ 5.9798e-01,  6.6718e-03,  2.5939e+00],\n",
       "          [ 4.8032e-01, -8.0732e-02,  2.6007e+00]],\n",
       " \n",
       "         [[ 6.0597e-01, -1.4461e-01,  2.5713e+00],\n",
       "          [ 5.0704e-01,  7.4164e-03,  2.4880e+00],\n",
       "          [ 3.2313e-01,  3.4945e-02,  2.4489e+00],\n",
       "          ...,\n",
       "          [ 5.6291e-01, -1.3871e-01,  2.6150e+00],\n",
       "          [ 5.9125e-01, -2.4380e-03,  2.6012e+00],\n",
       "          [ 4.6972e-01, -8.5030e-02,  2.6060e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-9.6507e-02, -6.5938e-02,  2.5990e+00],\n",
       "          [-7.9981e-02,  9.4543e-02,  2.4813e+00],\n",
       "          [-2.4910e-01,  1.1836e-01,  2.4303e+00],\n",
       "          ...,\n",
       "          [-1.3346e-01, -2.6088e-02,  2.6304e+00],\n",
       "          [-2.1599e-02,  6.0719e-02,  2.6172e+00],\n",
       "          [-1.6836e-01,  6.9385e-02,  2.5976e+00]],\n",
       " \n",
       "         [[-8.7130e-02, -7.1419e-02,  2.5861e+00],\n",
       "          [-7.1112e-02,  9.3418e-02,  2.4775e+00],\n",
       "          [-2.4173e-01,  1.1751e-01,  2.4237e+00],\n",
       "          ...,\n",
       "          [-1.2404e-01, -3.3904e-02,  2.6203e+00],\n",
       "          [-1.2276e-02,  5.3238e-02,  2.6130e+00],\n",
       "          [-1.5826e-01,  6.4527e-02,  2.5934e+00]],\n",
       " \n",
       "         [[-8.0026e-02, -7.4790e-02,  2.5806e+00],\n",
       "          [-6.9029e-02,  9.0974e-02,  2.4738e+00],\n",
       "          [-2.4229e-01,  1.1356e-01,  2.4135e+00],\n",
       "          ...,\n",
       "          [-1.1741e-01, -3.8853e-02,  2.6158e+00],\n",
       "          [-7.7044e-03,  5.0688e-02,  2.6094e+00],\n",
       "          [-1.5355e-01,  5.9402e-02,  2.5910e+00]]]),\n",
       " 'a2m': tensor([[[ 0.5119,  0.0211,  1.9618],\n",
       "          [ 0.5231,  0.0176,  2.4659],\n",
       "          [ 0.3360,  0.0405,  2.4177],\n",
       "          ...,\n",
       "          [ 0.7644,  0.2414,  1.1997],\n",
       "          [ 0.4691,  0.1681,  1.1074],\n",
       "          [ 0.5829, -0.0451,  2.7159]],\n",
       " \n",
       "         [[ 0.5048,  0.0292,  1.9772],\n",
       "          [ 0.5116,  0.0114,  2.4795],\n",
       "          [ 0.3263,  0.0362,  2.4357],\n",
       "          ...,\n",
       "          [ 0.7571,  0.2446,  1.2535],\n",
       "          [ 0.4913,  0.1439,  1.1076],\n",
       "          [ 0.5652, -0.0510,  2.7294]],\n",
       " \n",
       "         [[ 0.5019,  0.0469,  1.9894],\n",
       "          [ 0.5070,  0.0074,  2.4880],\n",
       "          [ 0.3231,  0.0349,  2.4489],\n",
       "          ...,\n",
       "          [ 0.7422,  0.2549,  1.3156],\n",
       "          [ 0.5181,  0.1191,  1.1086],\n",
       "          [ 0.5537, -0.0587,  2.7360]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0777,  0.1109,  1.9681],\n",
       "          [-0.0800,  0.0945,  2.4813],\n",
       "          [-0.2491,  0.1184,  2.4303],\n",
       "          ...,\n",
       "          [ 0.1708,  0.2649,  1.1014],\n",
       "          [-0.3458,  0.2393,  1.0820],\n",
       "          [-0.1100,  0.0638,  2.7419]],\n",
       " \n",
       "         [[-0.0689,  0.1180,  1.9634],\n",
       "          [-0.0711,  0.0934,  2.4775],\n",
       "          [-0.2417,  0.1175,  2.4237],\n",
       "          ...,\n",
       "          [ 0.1814,  0.2768,  1.0963],\n",
       "          [-0.3353,  0.2505,  1.0795],\n",
       "          [-0.1006,  0.0488,  2.7369]],\n",
       " \n",
       "         [[-0.0646,  0.1209,  1.9598],\n",
       "          [-0.0690,  0.0910,  2.4738],\n",
       "          [-0.2423,  0.1136,  2.4135],\n",
       "          ...,\n",
       "          [ 0.1879,  0.2818,  1.0931],\n",
       "          [-0.3347,  0.2523,  1.0784],\n",
       "          [-0.0948,  0.0424,  2.7334]]]),\n",
       " 'smpl': tensor([[[ 5.1190e-01,  2.1078e-02,  1.9618e+00],\n",
       "          [ 5.8742e-01,  2.0037e-02,  1.8750e+00],\n",
       "          [ 4.5058e-01,  1.3774e-02,  1.8671e+00],\n",
       "          ...,\n",
       "          [ 3.4739e-01, -1.1398e-01,  2.3004e+00],\n",
       "          [ 6.3436e-01, -1.6097e-01,  2.3482e+00],\n",
       "          [ 4.1425e-01, -1.6587e-01,  2.3124e+00]],\n",
       " \n",
       "         [[ 5.0476e-01,  2.9204e-02,  1.9772e+00],\n",
       "          [ 5.8280e-01,  2.6000e-02,  1.8928e+00],\n",
       "          [ 4.4614e-01,  2.3470e-02,  1.8807e+00],\n",
       "          ...,\n",
       "          [ 3.2488e-01, -1.0665e-01,  2.3186e+00],\n",
       "          [ 6.2666e-01, -1.5678e-01,  2.3724e+00],\n",
       "          [ 3.9353e-01, -1.5741e-01,  2.3223e+00]],\n",
       " \n",
       "         [[ 5.0190e-01,  4.6898e-02,  1.9894e+00],\n",
       "          [ 5.8187e-01,  4.1315e-02,  1.9068e+00],\n",
       "          [ 4.4554e-01,  4.3220e-02,  1.8914e+00],\n",
       "          ...,\n",
       "          [ 3.0287e-01, -1.0705e-01,  2.3207e+00],\n",
       "          [ 6.1451e-01, -1.6694e-01,  2.3866e+00],\n",
       "          [ 3.7097e-01, -1.5734e-01,  2.3089e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-7.7746e-02,  1.1088e-01,  1.9681e+00],\n",
       "          [-9.7145e-03,  1.1888e-01,  1.8757e+00],\n",
       "          [-1.4684e-01,  1.2244e-01,  1.8793e+00],\n",
       "          ...,\n",
       "          [-3.1148e-01, -1.6636e-01,  2.3036e+00],\n",
       "          [ 8.5953e-02, -1.6364e-01,  2.3249e+00],\n",
       "          [-2.6310e-01, -2.3134e-01,  2.2764e+00]],\n",
       " \n",
       "         [[-6.8903e-02,  1.1797e-01,  1.9634e+00],\n",
       "          [-9.4606e-04,  1.2987e-01,  1.8713e+00],\n",
       "          [-1.3808e-01,  1.3275e-01,  1.8751e+00],\n",
       "          ...,\n",
       "          [-3.6318e-01, -8.2883e-02,  2.1161e+00],\n",
       "          [ 1.0851e-01, -5.0149e-02,  2.1427e+00],\n",
       "          [-3.3217e-01, -1.2607e-01,  2.0492e+00]],\n",
       " \n",
       "         [[-6.4608e-02,  1.2094e-01,  1.9598e+00],\n",
       "          [ 3.4257e-03,  1.3499e-01,  1.8681e+00],\n",
       "          [-1.3374e-01,  1.3619e-01,  1.8716e+00],\n",
       "          ...,\n",
       "          [-3.7997e-01, -1.5767e-02,  2.0368e+00],\n",
       "          [ 1.0279e-01,  2.7096e-03,  2.0713e+00],\n",
       "          [-3.5595e-01, -4.3137e-02,  1.9594e+00]]]),\n",
       " 'a2mpl': tensor([[[ 5.1190e-01,  2.1078e-02,  1.9618e+00],\n",
       "          [ 5.8742e-01,  2.0037e-02,  1.8750e+00],\n",
       "          [ 4.5058e-01,  1.3774e-02,  1.8671e+00],\n",
       "          ...,\n",
       "          [ 7.6437e-01,  2.4145e-01,  1.1997e+00],\n",
       "          [ 4.6915e-01,  1.6813e-01,  1.1074e+00],\n",
       "          [ 5.8294e-01, -4.5128e-02,  2.7159e+00]],\n",
       " \n",
       "         [[ 5.0476e-01,  2.9204e-02,  1.9772e+00],\n",
       "          [ 5.8280e-01,  2.6000e-02,  1.8928e+00],\n",
       "          [ 4.4614e-01,  2.3470e-02,  1.8807e+00],\n",
       "          ...,\n",
       "          [ 7.5714e-01,  2.4462e-01,  1.2535e+00],\n",
       "          [ 4.9129e-01,  1.4391e-01,  1.1076e+00],\n",
       "          [ 5.6518e-01, -5.1037e-02,  2.7294e+00]],\n",
       " \n",
       "         [[ 5.0190e-01,  4.6898e-02,  1.9894e+00],\n",
       "          [ 5.8187e-01,  4.1315e-02,  1.9068e+00],\n",
       "          [ 4.4554e-01,  4.3220e-02,  1.8914e+00],\n",
       "          ...,\n",
       "          [ 7.4219e-01,  2.5491e-01,  1.3156e+00],\n",
       "          [ 5.1812e-01,  1.1909e-01,  1.1086e+00],\n",
       "          [ 5.5365e-01, -5.8701e-02,  2.7360e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-7.7746e-02,  1.1088e-01,  1.9681e+00],\n",
       "          [-9.7145e-03,  1.1888e-01,  1.8757e+00],\n",
       "          [-1.4684e-01,  1.2244e-01,  1.8793e+00],\n",
       "          ...,\n",
       "          [ 1.7081e-01,  2.6486e-01,  1.1014e+00],\n",
       "          [-3.4580e-01,  2.3930e-01,  1.0820e+00],\n",
       "          [-1.0999e-01,  6.3767e-02,  2.7419e+00]],\n",
       " \n",
       "         [[-6.8903e-02,  1.1797e-01,  1.9634e+00],\n",
       "          [-9.4606e-04,  1.2987e-01,  1.8713e+00],\n",
       "          [-1.3808e-01,  1.3275e-01,  1.8751e+00],\n",
       "          ...,\n",
       "          [ 1.8139e-01,  2.7681e-01,  1.0963e+00],\n",
       "          [-3.3532e-01,  2.5051e-01,  1.0795e+00],\n",
       "          [-1.0060e-01,  4.8787e-02,  2.7369e+00]],\n",
       " \n",
       "         [[-6.4608e-02,  1.2094e-01,  1.9598e+00],\n",
       "          [ 3.4257e-03,  1.3499e-01,  1.8681e+00],\n",
       "          [-1.3374e-01,  1.3619e-01,  1.8716e+00],\n",
       "          ...,\n",
       "          [ 1.8794e-01,  2.8178e-01,  1.0931e+00],\n",
       "          [-3.3465e-01,  2.5228e-01,  1.0784e+00],\n",
       "          [-9.4829e-02,  4.2443e-02,  2.7334e+00]]])}"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7d8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
